{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "im = pd.read_csv('data/immune/raw/SKCM_Immune.txt', sep='\\t')\n",
    "survival = pd.read_csv('./data/immune/raw/SKCM_Survival.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCGA-D3-A3CE</th>\n",
       "      <th>TCGA-D9-A6E9</th>\n",
       "      <th>TCGA-FR-A729</th>\n",
       "      <th>TCGA-D3-A3CF</th>\n",
       "      <th>TCGA-WE-AA9Y</th>\n",
       "      <th>TCGA-D3-A3CC</th>\n",
       "      <th>TCGA-Z2-AA3V</th>\n",
       "      <th>TCGA-GN-A8LL</th>\n",
       "      <th>TCGA-GN-A8LK</th>\n",
       "      <th>TCGA-FS-A1ZS</th>\n",
       "      <th>...</th>\n",
       "      <th>TCGA-EE-A2M5</th>\n",
       "      <th>TCGA-D3-A5GL</th>\n",
       "      <th>TCGA-EE-A2M7</th>\n",
       "      <th>TCGA-EE-A2M6</th>\n",
       "      <th>TCGA-D9-A3Z1</th>\n",
       "      <th>TCGA-D9-A3Z3</th>\n",
       "      <th>TCGA-EE-A3J7</th>\n",
       "      <th>TCGA-EE-A3AF</th>\n",
       "      <th>TCGA-EE-A2M8</th>\n",
       "      <th>TCGA-GF-A6C9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CSMD2</th>\n",
       "      <td>-0.054080</td>\n",
       "      <td>-0.229752</td>\n",
       "      <td>-0.195151</td>\n",
       "      <td>-0.127083</td>\n",
       "      <td>0.416151</td>\n",
       "      <td>-0.156377</td>\n",
       "      <td>-0.246390</td>\n",
       "      <td>-0.297175</td>\n",
       "      <td>-0.224577</td>\n",
       "      <td>14.230808</td>\n",
       "      <td>...</td>\n",
       "      <td>7.849712</td>\n",
       "      <td>-0.155544</td>\n",
       "      <td>-0.246903</td>\n",
       "      <td>-0.283339</td>\n",
       "      <td>-0.104239</td>\n",
       "      <td>-0.173656</td>\n",
       "      <td>-0.162199</td>\n",
       "      <td>-0.148308</td>\n",
       "      <td>-0.045141</td>\n",
       "      <td>0.433603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZC3H12D</th>\n",
       "      <td>-0.062392</td>\n",
       "      <td>0.787136</td>\n",
       "      <td>1.198162</td>\n",
       "      <td>0.525882</td>\n",
       "      <td>-0.155966</td>\n",
       "      <td>-0.346858</td>\n",
       "      <td>0.678543</td>\n",
       "      <td>-0.486661</td>\n",
       "      <td>-0.475804</td>\n",
       "      <td>-0.440953</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.401698</td>\n",
       "      <td>-0.484379</td>\n",
       "      <td>0.023117</td>\n",
       "      <td>-0.290790</td>\n",
       "      <td>0.175650</td>\n",
       "      <td>0.678512</td>\n",
       "      <td>-0.407778</td>\n",
       "      <td>-0.289600</td>\n",
       "      <td>1.769030</td>\n",
       "      <td>1.608189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KLF15</th>\n",
       "      <td>-0.285557</td>\n",
       "      <td>-0.925922</td>\n",
       "      <td>-0.094339</td>\n",
       "      <td>-0.945225</td>\n",
       "      <td>2.075588</td>\n",
       "      <td>0.052303</td>\n",
       "      <td>0.846139</td>\n",
       "      <td>1.212722</td>\n",
       "      <td>-0.419437</td>\n",
       "      <td>-1.190301</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.198349</td>\n",
       "      <td>-0.739588</td>\n",
       "      <td>0.785233</td>\n",
       "      <td>-0.075452</td>\n",
       "      <td>-0.838268</td>\n",
       "      <td>-0.032067</td>\n",
       "      <td>3.523628</td>\n",
       "      <td>0.981693</td>\n",
       "      <td>-0.790780</td>\n",
       "      <td>-0.560695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRPL30</th>\n",
       "      <td>-1.103459</td>\n",
       "      <td>0.292058</td>\n",
       "      <td>1.357681</td>\n",
       "      <td>1.485900</td>\n",
       "      <td>0.622276</td>\n",
       "      <td>-0.069789</td>\n",
       "      <td>-1.869262</td>\n",
       "      <td>-0.388936</td>\n",
       "      <td>-0.312104</td>\n",
       "      <td>-0.999960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062576</td>\n",
       "      <td>0.304411</td>\n",
       "      <td>-0.620333</td>\n",
       "      <td>2.073774</td>\n",
       "      <td>0.047338</td>\n",
       "      <td>-1.527091</td>\n",
       "      <td>-0.306298</td>\n",
       "      <td>-1.364359</td>\n",
       "      <td>-0.513214</td>\n",
       "      <td>-0.786474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UCK1</th>\n",
       "      <td>-0.566261</td>\n",
       "      <td>0.194461</td>\n",
       "      <td>-0.750406</td>\n",
       "      <td>0.675687</td>\n",
       "      <td>0.012524</td>\n",
       "      <td>-0.675303</td>\n",
       "      <td>4.375373</td>\n",
       "      <td>1.203905</td>\n",
       "      <td>2.453245</td>\n",
       "      <td>-1.252481</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.632063</td>\n",
       "      <td>-0.559619</td>\n",
       "      <td>-0.579764</td>\n",
       "      <td>-0.685455</td>\n",
       "      <td>0.443639</td>\n",
       "      <td>1.110279</td>\n",
       "      <td>-0.337508</td>\n",
       "      <td>-0.905385</td>\n",
       "      <td>-0.589339</td>\n",
       "      <td>-0.615289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD8A</th>\n",
       "      <td>0.515832</td>\n",
       "      <td>3.633196</td>\n",
       "      <td>0.818810</td>\n",
       "      <td>-0.176498</td>\n",
       "      <td>-0.451516</td>\n",
       "      <td>-0.522069</td>\n",
       "      <td>-0.002288</td>\n",
       "      <td>-0.460104</td>\n",
       "      <td>-0.521519</td>\n",
       "      <td>-0.512798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046678</td>\n",
       "      <td>-0.519461</td>\n",
       "      <td>-0.397443</td>\n",
       "      <td>-0.433215</td>\n",
       "      <td>0.279004</td>\n",
       "      <td>-0.296561</td>\n",
       "      <td>-0.347329</td>\n",
       "      <td>-0.241276</td>\n",
       "      <td>3.818453</td>\n",
       "      <td>-0.162707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD8B</th>\n",
       "      <td>0.220158</td>\n",
       "      <td>4.561195</td>\n",
       "      <td>0.921434</td>\n",
       "      <td>-0.227858</td>\n",
       "      <td>-0.429290</td>\n",
       "      <td>-0.511012</td>\n",
       "      <td>0.500421</td>\n",
       "      <td>-0.449870</td>\n",
       "      <td>-0.518489</td>\n",
       "      <td>-0.520821</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162957</td>\n",
       "      <td>-0.511192</td>\n",
       "      <td>-0.261121</td>\n",
       "      <td>-0.453047</td>\n",
       "      <td>0.275589</td>\n",
       "      <td>-0.277537</td>\n",
       "      <td>-0.359942</td>\n",
       "      <td>-0.266876</td>\n",
       "      <td>3.902101</td>\n",
       "      <td>-0.084617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GZMA</th>\n",
       "      <td>0.169125</td>\n",
       "      <td>2.111791</td>\n",
       "      <td>0.711730</td>\n",
       "      <td>-0.140605</td>\n",
       "      <td>-0.362708</td>\n",
       "      <td>-0.531611</td>\n",
       "      <td>0.283079</td>\n",
       "      <td>-0.527910</td>\n",
       "      <td>-0.555377</td>\n",
       "      <td>-0.519452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024211</td>\n",
       "      <td>-0.552516</td>\n",
       "      <td>-0.447693</td>\n",
       "      <td>-0.433737</td>\n",
       "      <td>0.714233</td>\n",
       "      <td>-0.083080</td>\n",
       "      <td>-0.385502</td>\n",
       "      <td>-0.305114</td>\n",
       "      <td>2.291183</td>\n",
       "      <td>0.019123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GZMB</th>\n",
       "      <td>-0.051636</td>\n",
       "      <td>6.575586</td>\n",
       "      <td>0.515839</td>\n",
       "      <td>-0.018477</td>\n",
       "      <td>-0.315049</td>\n",
       "      <td>-0.489974</td>\n",
       "      <td>1.127235</td>\n",
       "      <td>-0.431023</td>\n",
       "      <td>-0.492219</td>\n",
       "      <td>-0.396725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613315</td>\n",
       "      <td>-0.480637</td>\n",
       "      <td>-0.442818</td>\n",
       "      <td>-0.336062</td>\n",
       "      <td>0.464937</td>\n",
       "      <td>-0.249683</td>\n",
       "      <td>-0.396567</td>\n",
       "      <td>-0.351070</td>\n",
       "      <td>0.291201</td>\n",
       "      <td>0.297645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRF1</th>\n",
       "      <td>0.279281</td>\n",
       "      <td>6.064225</td>\n",
       "      <td>0.572005</td>\n",
       "      <td>-0.206566</td>\n",
       "      <td>-0.372088</td>\n",
       "      <td>-0.483672</td>\n",
       "      <td>2.832222</td>\n",
       "      <td>-0.344526</td>\n",
       "      <td>-0.486797</td>\n",
       "      <td>-0.477997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125416</td>\n",
       "      <td>-0.472934</td>\n",
       "      <td>-0.361238</td>\n",
       "      <td>-0.377179</td>\n",
       "      <td>0.674092</td>\n",
       "      <td>-0.235528</td>\n",
       "      <td>-0.291784</td>\n",
       "      <td>-0.297436</td>\n",
       "      <td>2.324674</td>\n",
       "      <td>0.076410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1386 rows × 314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TCGA-D3-A3CE  TCGA-D9-A6E9  TCGA-FR-A729  TCGA-D3-A3CF  TCGA-WE-AA9Y  \\\n",
       "CSMD2       -0.054080     -0.229752     -0.195151     -0.127083      0.416151   \n",
       "ZC3H12D     -0.062392      0.787136      1.198162      0.525882     -0.155966   \n",
       "KLF15       -0.285557     -0.925922     -0.094339     -0.945225      2.075588   \n",
       "MRPL30      -1.103459      0.292058      1.357681      1.485900      0.622276   \n",
       "UCK1        -0.566261      0.194461     -0.750406      0.675687      0.012524   \n",
       "...               ...           ...           ...           ...           ...   \n",
       "CD8A         0.515832      3.633196      0.818810     -0.176498     -0.451516   \n",
       "CD8B         0.220158      4.561195      0.921434     -0.227858     -0.429290   \n",
       "GZMA         0.169125      2.111791      0.711730     -0.140605     -0.362708   \n",
       "GZMB        -0.051636      6.575586      0.515839     -0.018477     -0.315049   \n",
       "PRF1         0.279281      6.064225      0.572005     -0.206566     -0.372088   \n",
       "\n",
       "         TCGA-D3-A3CC  TCGA-Z2-AA3V  TCGA-GN-A8LL  TCGA-GN-A8LK  TCGA-FS-A1ZS  \\\n",
       "CSMD2       -0.156377     -0.246390     -0.297175     -0.224577     14.230808   \n",
       "ZC3H12D     -0.346858      0.678543     -0.486661     -0.475804     -0.440953   \n",
       "KLF15        0.052303      0.846139      1.212722     -0.419437     -1.190301   \n",
       "MRPL30      -0.069789     -1.869262     -0.388936     -0.312104     -0.999960   \n",
       "UCK1        -0.675303      4.375373      1.203905      2.453245     -1.252481   \n",
       "...               ...           ...           ...           ...           ...   \n",
       "CD8A        -0.522069     -0.002288     -0.460104     -0.521519     -0.512798   \n",
       "CD8B        -0.511012      0.500421     -0.449870     -0.518489     -0.520821   \n",
       "GZMA        -0.531611      0.283079     -0.527910     -0.555377     -0.519452   \n",
       "GZMB        -0.489974      1.127235     -0.431023     -0.492219     -0.396725   \n",
       "PRF1        -0.483672      2.832222     -0.344526     -0.486797     -0.477997   \n",
       "\n",
       "         ...  TCGA-EE-A2M5  TCGA-D3-A5GL  TCGA-EE-A2M7  TCGA-EE-A2M6  \\\n",
       "CSMD2    ...      7.849712     -0.155544     -0.246903     -0.283339   \n",
       "ZC3H12D  ...     -0.401698     -0.484379      0.023117     -0.290790   \n",
       "KLF15    ...     -1.198349     -0.739588      0.785233     -0.075452   \n",
       "MRPL30   ...     -0.062576      0.304411     -0.620333      2.073774   \n",
       "UCK1     ...     -0.632063     -0.559619     -0.579764     -0.685455   \n",
       "...      ...           ...           ...           ...           ...   \n",
       "CD8A     ...     -0.046678     -0.519461     -0.397443     -0.433215   \n",
       "CD8B     ...     -0.162957     -0.511192     -0.261121     -0.453047   \n",
       "GZMA     ...      0.024211     -0.552516     -0.447693     -0.433737   \n",
       "GZMB     ...      0.613315     -0.480637     -0.442818     -0.336062   \n",
       "PRF1     ...      0.125416     -0.472934     -0.361238     -0.377179   \n",
       "\n",
       "         TCGA-D9-A3Z1  TCGA-D9-A3Z3  TCGA-EE-A3J7  TCGA-EE-A3AF  TCGA-EE-A2M8  \\\n",
       "CSMD2       -0.104239     -0.173656     -0.162199     -0.148308     -0.045141   \n",
       "ZC3H12D      0.175650      0.678512     -0.407778     -0.289600      1.769030   \n",
       "KLF15       -0.838268     -0.032067      3.523628      0.981693     -0.790780   \n",
       "MRPL30       0.047338     -1.527091     -0.306298     -1.364359     -0.513214   \n",
       "UCK1         0.443639      1.110279     -0.337508     -0.905385     -0.589339   \n",
       "...               ...           ...           ...           ...           ...   \n",
       "CD8A         0.279004     -0.296561     -0.347329     -0.241276      3.818453   \n",
       "CD8B         0.275589     -0.277537     -0.359942     -0.266876      3.902101   \n",
       "GZMA         0.714233     -0.083080     -0.385502     -0.305114      2.291183   \n",
       "GZMB         0.464937     -0.249683     -0.396567     -0.351070      0.291201   \n",
       "PRF1         0.674092     -0.235528     -0.291784     -0.297436      2.324674   \n",
       "\n",
       "         TCGA-GF-A6C9  \n",
       "CSMD2        0.433603  \n",
       "ZC3H12D      1.608189  \n",
       "KLF15       -0.560695  \n",
       "MRPL30      -0.786474  \n",
       "UCK1        -0.615289  \n",
       "...               ...  \n",
       "CD8A        -0.162707  \n",
       "CD8B        -0.084617  \n",
       "GZMA         0.019123  \n",
       "GZMB         0.297645  \n",
       "PRF1         0.076410  \n",
       "\n",
       "[1386 rows x 314 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230, 1386)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = survival['group'] != 'Unknown'\n",
    "\n",
    "X = im[im.columns[mask]].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = survival[mask]['group'].replace({'Low': 0, 'High': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CSMD2</th>\n",
       "      <th>ZC3H12D</th>\n",
       "      <th>KLF15</th>\n",
       "      <th>MRPL30</th>\n",
       "      <th>UCK1</th>\n",
       "      <th>AMPD3</th>\n",
       "      <th>LRP10</th>\n",
       "      <th>CDYL2</th>\n",
       "      <th>NLGN1</th>\n",
       "      <th>TSEN2</th>\n",
       "      <th>...</th>\n",
       "      <th>COL6A2</th>\n",
       "      <th>COL6A3</th>\n",
       "      <th>COL6A1</th>\n",
       "      <th>COL8A2</th>\n",
       "      <th>C11orf88</th>\n",
       "      <th>CD8A</th>\n",
       "      <th>CD8B</th>\n",
       "      <th>GZMA</th>\n",
       "      <th>GZMB</th>\n",
       "      <th>PRF1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-D3-A3CE</th>\n",
       "      <td>-0.054080</td>\n",
       "      <td>-0.062392</td>\n",
       "      <td>-0.285557</td>\n",
       "      <td>-1.103459</td>\n",
       "      <td>-0.566261</td>\n",
       "      <td>-0.292860</td>\n",
       "      <td>-0.601413</td>\n",
       "      <td>-0.086753</td>\n",
       "      <td>-0.610128</td>\n",
       "      <td>-0.370984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.307429</td>\n",
       "      <td>-0.093698</td>\n",
       "      <td>-0.326143</td>\n",
       "      <td>-0.482138</td>\n",
       "      <td>0.002873</td>\n",
       "      <td>0.515832</td>\n",
       "      <td>0.220158</td>\n",
       "      <td>0.169125</td>\n",
       "      <td>-0.051636</td>\n",
       "      <td>0.279281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-FR-A729</th>\n",
       "      <td>-0.195151</td>\n",
       "      <td>1.198162</td>\n",
       "      <td>-0.094339</td>\n",
       "      <td>1.357681</td>\n",
       "      <td>-0.750406</td>\n",
       "      <td>0.350193</td>\n",
       "      <td>-0.935906</td>\n",
       "      <td>-0.173981</td>\n",
       "      <td>0.949952</td>\n",
       "      <td>-0.034250</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.364431</td>\n",
       "      <td>-0.196027</td>\n",
       "      <td>-0.232056</td>\n",
       "      <td>-0.482473</td>\n",
       "      <td>-0.161506</td>\n",
       "      <td>0.818810</td>\n",
       "      <td>0.921434</td>\n",
       "      <td>0.711730</td>\n",
       "      <td>0.515839</td>\n",
       "      <td>0.572005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-D3-A3CF</th>\n",
       "      <td>-0.127083</td>\n",
       "      <td>0.525882</td>\n",
       "      <td>-0.945225</td>\n",
       "      <td>1.485900</td>\n",
       "      <td>0.675687</td>\n",
       "      <td>0.852886</td>\n",
       "      <td>0.130814</td>\n",
       "      <td>-0.259794</td>\n",
       "      <td>0.046976</td>\n",
       "      <td>-0.497017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.278719</td>\n",
       "      <td>0.061514</td>\n",
       "      <td>-0.274250</td>\n",
       "      <td>-0.406437</td>\n",
       "      <td>0.024995</td>\n",
       "      <td>-0.176498</td>\n",
       "      <td>-0.227858</td>\n",
       "      <td>-0.140605</td>\n",
       "      <td>-0.018477</td>\n",
       "      <td>-0.206566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-D3-A3CC</th>\n",
       "      <td>-0.156377</td>\n",
       "      <td>-0.346858</td>\n",
       "      <td>0.052303</td>\n",
       "      <td>-0.069789</td>\n",
       "      <td>-0.675303</td>\n",
       "      <td>-0.487027</td>\n",
       "      <td>-0.037188</td>\n",
       "      <td>-0.279064</td>\n",
       "      <td>0.529820</td>\n",
       "      <td>0.421326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218611</td>\n",
       "      <td>-0.083701</td>\n",
       "      <td>-0.231938</td>\n",
       "      <td>-0.300146</td>\n",
       "      <td>-0.043317</td>\n",
       "      <td>-0.522069</td>\n",
       "      <td>-0.511012</td>\n",
       "      <td>-0.531611</td>\n",
       "      <td>-0.489974</td>\n",
       "      <td>-0.483672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-GN-A8LL</th>\n",
       "      <td>-0.297175</td>\n",
       "      <td>-0.486661</td>\n",
       "      <td>1.212722</td>\n",
       "      <td>-0.388936</td>\n",
       "      <td>1.203905</td>\n",
       "      <td>-0.599737</td>\n",
       "      <td>-0.426903</td>\n",
       "      <td>-0.541385</td>\n",
       "      <td>-0.168366</td>\n",
       "      <td>0.073776</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.323900</td>\n",
       "      <td>-0.409755</td>\n",
       "      <td>-0.412275</td>\n",
       "      <td>-0.554630</td>\n",
       "      <td>0.101585</td>\n",
       "      <td>-0.460104</td>\n",
       "      <td>-0.449870</td>\n",
       "      <td>-0.527910</td>\n",
       "      <td>-0.431023</td>\n",
       "      <td>-0.344526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-EE-A2M7</th>\n",
       "      <td>-0.246903</td>\n",
       "      <td>0.023117</td>\n",
       "      <td>0.785233</td>\n",
       "      <td>-0.620333</td>\n",
       "      <td>-0.579764</td>\n",
       "      <td>-0.171466</td>\n",
       "      <td>-0.433517</td>\n",
       "      <td>-0.024845</td>\n",
       "      <td>-0.007897</td>\n",
       "      <td>-1.236196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.537367</td>\n",
       "      <td>-0.304349</td>\n",
       "      <td>-0.422798</td>\n",
       "      <td>7.098040</td>\n",
       "      <td>-0.173772</td>\n",
       "      <td>-0.397443</td>\n",
       "      <td>-0.261121</td>\n",
       "      <td>-0.447693</td>\n",
       "      <td>-0.442818</td>\n",
       "      <td>-0.361238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-EE-A2M6</th>\n",
       "      <td>-0.283339</td>\n",
       "      <td>-0.290790</td>\n",
       "      <td>-0.075452</td>\n",
       "      <td>2.073774</td>\n",
       "      <td>-0.685455</td>\n",
       "      <td>0.355798</td>\n",
       "      <td>-1.441081</td>\n",
       "      <td>-0.172193</td>\n",
       "      <td>-0.387770</td>\n",
       "      <td>-0.837741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.568789</td>\n",
       "      <td>-0.400618</td>\n",
       "      <td>-0.508305</td>\n",
       "      <td>-0.419480</td>\n",
       "      <td>-0.257365</td>\n",
       "      <td>-0.433215</td>\n",
       "      <td>-0.453047</td>\n",
       "      <td>-0.433737</td>\n",
       "      <td>-0.336062</td>\n",
       "      <td>-0.377179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-D9-A3Z1</th>\n",
       "      <td>-0.104239</td>\n",
       "      <td>0.175650</td>\n",
       "      <td>-0.838268</td>\n",
       "      <td>0.047338</td>\n",
       "      <td>0.443639</td>\n",
       "      <td>0.019480</td>\n",
       "      <td>0.584137</td>\n",
       "      <td>0.349473</td>\n",
       "      <td>-0.874513</td>\n",
       "      <td>-0.861467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.444091</td>\n",
       "      <td>-0.096881</td>\n",
       "      <td>-0.419314</td>\n",
       "      <td>-0.492728</td>\n",
       "      <td>-0.257365</td>\n",
       "      <td>0.279004</td>\n",
       "      <td>0.275589</td>\n",
       "      <td>0.714233</td>\n",
       "      <td>0.464937</td>\n",
       "      <td>0.674092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-EE-A3AF</th>\n",
       "      <td>-0.148308</td>\n",
       "      <td>-0.289600</td>\n",
       "      <td>0.981693</td>\n",
       "      <td>-1.364359</td>\n",
       "      <td>-0.905385</td>\n",
       "      <td>-0.058858</td>\n",
       "      <td>1.561959</td>\n",
       "      <td>-0.366715</td>\n",
       "      <td>0.169013</td>\n",
       "      <td>-0.072336</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.375040</td>\n",
       "      <td>-0.122932</td>\n",
       "      <td>-0.300658</td>\n",
       "      <td>0.016861</td>\n",
       "      <td>-0.168045</td>\n",
       "      <td>-0.241276</td>\n",
       "      <td>-0.266876</td>\n",
       "      <td>-0.305114</td>\n",
       "      <td>-0.351070</td>\n",
       "      <td>-0.297436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-EE-A2M8</th>\n",
       "      <td>-0.045141</td>\n",
       "      <td>1.769030</td>\n",
       "      <td>-0.790780</td>\n",
       "      <td>-0.513214</td>\n",
       "      <td>-0.589339</td>\n",
       "      <td>1.975108</td>\n",
       "      <td>-0.219482</td>\n",
       "      <td>0.631542</td>\n",
       "      <td>-0.694794</td>\n",
       "      <td>-1.591198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276730</td>\n",
       "      <td>0.166242</td>\n",
       "      <td>-0.328936</td>\n",
       "      <td>0.868619</td>\n",
       "      <td>0.788806</td>\n",
       "      <td>3.818453</td>\n",
       "      <td>3.902101</td>\n",
       "      <td>2.291183</td>\n",
       "      <td>0.291201</td>\n",
       "      <td>2.324674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows × 1386 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 CSMD2   ZC3H12D     KLF15    MRPL30      UCK1     AMPD3  \\\n",
       "TCGA-D3-A3CE -0.054080 -0.062392 -0.285557 -1.103459 -0.566261 -0.292860   \n",
       "TCGA-FR-A729 -0.195151  1.198162 -0.094339  1.357681 -0.750406  0.350193   \n",
       "TCGA-D3-A3CF -0.127083  0.525882 -0.945225  1.485900  0.675687  0.852886   \n",
       "TCGA-D3-A3CC -0.156377 -0.346858  0.052303 -0.069789 -0.675303 -0.487027   \n",
       "TCGA-GN-A8LL -0.297175 -0.486661  1.212722 -0.388936  1.203905 -0.599737   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "TCGA-EE-A2M7 -0.246903  0.023117  0.785233 -0.620333 -0.579764 -0.171466   \n",
       "TCGA-EE-A2M6 -0.283339 -0.290790 -0.075452  2.073774 -0.685455  0.355798   \n",
       "TCGA-D9-A3Z1 -0.104239  0.175650 -0.838268  0.047338  0.443639  0.019480   \n",
       "TCGA-EE-A3AF -0.148308 -0.289600  0.981693 -1.364359 -0.905385 -0.058858   \n",
       "TCGA-EE-A2M8 -0.045141  1.769030 -0.790780 -0.513214 -0.589339  1.975108   \n",
       "\n",
       "                 LRP10     CDYL2     NLGN1     TSEN2  ...    COL6A2    COL6A3  \\\n",
       "TCGA-D3-A3CE -0.601413 -0.086753 -0.610128 -0.370984  ... -0.307429 -0.093698   \n",
       "TCGA-FR-A729 -0.935906 -0.173981  0.949952 -0.034250  ... -0.364431 -0.196027   \n",
       "TCGA-D3-A3CF  0.130814 -0.259794  0.046976 -0.497017  ... -0.278719  0.061514   \n",
       "TCGA-D3-A3CC -0.037188 -0.279064  0.529820  0.421326  ... -0.218611 -0.083701   \n",
       "TCGA-GN-A8LL -0.426903 -0.541385 -0.168366  0.073776  ... -0.323900 -0.409755   \n",
       "...                ...       ...       ...       ...  ...       ...       ...   \n",
       "TCGA-EE-A2M7 -0.433517 -0.024845 -0.007897 -1.236196  ... -0.537367 -0.304349   \n",
       "TCGA-EE-A2M6 -1.441081 -0.172193 -0.387770 -0.837741  ... -0.568789 -0.400618   \n",
       "TCGA-D9-A3Z1  0.584137  0.349473 -0.874513 -0.861467  ... -0.444091 -0.096881   \n",
       "TCGA-EE-A3AF  1.561959 -0.366715  0.169013 -0.072336  ... -0.375040 -0.122932   \n",
       "TCGA-EE-A2M8 -0.219482  0.631542 -0.694794 -1.591198  ... -0.276730  0.166242   \n",
       "\n",
       "                COL6A1    COL8A2  C11orf88      CD8A      CD8B      GZMA  \\\n",
       "TCGA-D3-A3CE -0.326143 -0.482138  0.002873  0.515832  0.220158  0.169125   \n",
       "TCGA-FR-A729 -0.232056 -0.482473 -0.161506  0.818810  0.921434  0.711730   \n",
       "TCGA-D3-A3CF -0.274250 -0.406437  0.024995 -0.176498 -0.227858 -0.140605   \n",
       "TCGA-D3-A3CC -0.231938 -0.300146 -0.043317 -0.522069 -0.511012 -0.531611   \n",
       "TCGA-GN-A8LL -0.412275 -0.554630  0.101585 -0.460104 -0.449870 -0.527910   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "TCGA-EE-A2M7 -0.422798  7.098040 -0.173772 -0.397443 -0.261121 -0.447693   \n",
       "TCGA-EE-A2M6 -0.508305 -0.419480 -0.257365 -0.433215 -0.453047 -0.433737   \n",
       "TCGA-D9-A3Z1 -0.419314 -0.492728 -0.257365  0.279004  0.275589  0.714233   \n",
       "TCGA-EE-A3AF -0.300658  0.016861 -0.168045 -0.241276 -0.266876 -0.305114   \n",
       "TCGA-EE-A2M8 -0.328936  0.868619  0.788806  3.818453  3.902101  2.291183   \n",
       "\n",
       "                  GZMB      PRF1  \n",
       "TCGA-D3-A3CE -0.051636  0.279281  \n",
       "TCGA-FR-A729  0.515839  0.572005  \n",
       "TCGA-D3-A3CF -0.018477 -0.206566  \n",
       "TCGA-D3-A3CC -0.489974 -0.483672  \n",
       "TCGA-GN-A8LL -0.431023 -0.344526  \n",
       "...                ...       ...  \n",
       "TCGA-EE-A2M7 -0.442818 -0.361238  \n",
       "TCGA-EE-A2M6 -0.336062 -0.377179  \n",
       "TCGA-D9-A3Z1  0.464937  0.674092  \n",
       "TCGA-EE-A3AF -0.351070 -0.297436  \n",
       "TCGA-EE-A2M8  0.291201  2.324674  \n",
       "\n",
       "[230 rows x 1386 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "2      0\n",
       "3      1\n",
       "5      0\n",
       "7      1\n",
       "      ..\n",
       "306    1\n",
       "307    0\n",
       "308    1\n",
       "311    1\n",
       "312    1\n",
       "Name: group, Length: 230, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6521739130434783, 0.5652173913043479)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-y_train.sum()/len(y_train), 1-y_test.sum()/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature selction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "k_best = 50  # Select top 2 features\n",
    "selector = SelectKBest(score_func=chi2, k=k_best)\n",
    "X_new = selector.fit_transform(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230, 1386)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1386,)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.get_support().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04932207, 0.23538099, 0.00283438, ..., 0.00969803, 0.09953817,\n",
       "        0.        ],\n",
       "       [0.444412  , 0.18320657, 0.000756  , ..., 0.00642975, 0.02009712,\n",
       "        0.        ],\n",
       "       [0.22489742, 0.29082196, 0.00258468, ..., 0.10889729, 0.11022241,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.45289537, 0.19428963, 0.00204461, ..., 0.        , 0.05823109,\n",
       "        0.        ],\n",
       "       [0.25137608, 0.23771688, 0.0016605 , ..., 0.0079882 , 0.16491379,\n",
       "        0.        ],\n",
       "       [0.06758766, 0.47366343, 0.01213068, ..., 0.        , 0.00872941,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230, 50)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = survival[mask]['group'].replace({'Low': 0, 'High': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6521739130434783\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a binary classification model (e.g., Logistic Regression)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.782608695652174"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in y_pred:\n",
    "    sum += i\n",
    "1-sum/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5652173913043479, 0.6521739130434783)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "1-np.count_nonzero(y_test)/len(y_test), 1-np.count_nonzero(y_train)/len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5869565217391305, 0.75]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "svc = SVC().fit(X_train,y_train)\n",
    "\n",
    "y_prob = svc.decision_function(X_test)                              # 决策边界距离\n",
    "y_pred = svc.predict(X_test)                                        # 模型对测试集的预测结果\n",
    "fpr_svc,tpr_svc,threshold_svc = metrics.roc_curve(y_test,y_prob)     # 获取真阳率、伪阳率、阈值\n",
    "auc_svc = metrics.auc(fpr_svc,tpr_svc)                              # 模型准确率\n",
    "score_svc = metrics.accuracy_score(y_test,y_pred)\n",
    "print([score_svc,auc_svc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6086956521739131, 0.5807692307692308]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "knn = KNeighborsClassifier().fit(X_train,y_train)\n",
    "\n",
    "y_prob = knn.predict_proba(X_test)[:,1]                              \n",
    "y_pred = knn.predict(X_test)                                       \n",
    "fpr_knn,tpr_knn,threshold_knn = metrics.roc_curve(y_test,y_prob)   \n",
    "auc_knn = metrics.auc(fpr_knn,tpr_knn)                              \n",
    "score_knn = metrics.accuracy_score(y_test,y_pred)\n",
    "print([score_knn,auc_knn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=11时,得分最高=0.6956521739130435\n"
     ]
    }
   ],
   "source": [
    "score_K=[]\n",
    "KList=range(2,50)\n",
    "\n",
    "for k in KList:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k).fit(X_train,y_train)\n",
    "    score_K.append(knn.score(X_test,y_test))\n",
    "\n",
    "print('K={}时,得分最高={}'.format(KList[score_K.index(max(score_K))],max(score_K)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5652173913043478, 0.551923076923077]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "\n",
    "dtc = tree.DecisionTreeClassifier()                              # 建立决策树模型\n",
    "dtc.fit(X_train,y_train)                                         # 训练模型\n",
    "y_prob = dtc.predict_proba(X_test)[:,1]                          # 预测1类的概率\n",
    "y_pred = dtc.predict(X_test)                                     # 模型对测试集的预测结果 \n",
    "fpr_dtc,tpr_dtc,threshod_dtc= metrics.roc_curve(y_test,y_prob)   # 获取真阳率、伪阳率、阈值\n",
    "score_dtc = metrics.accuracy_score(y_test,y_pred)                \n",
    "auc_dtc = metrics.auc(fpr_dtc,tpr_dtc) \n",
    "print([score_dtc,auc_dtc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5652173913043478, 0.7221153846153846]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "rfc = RandomForestClassifier()                                     # 建立随机森林分类器\n",
    "rfc.fit(X_train,y_train)                                           # 训练随机森林模型\n",
    "y_prob = rfc.predict_proba(X_test)[:,1]                            # 预测1类的概率\n",
    "y_pred=rfc.predict(X_test)                                         # 模型对测试集的预测结果\n",
    "fpr_rfc,tpr_rfc,threshold_rfc = metrics.roc_curve(y_test,y_prob)   # 获取真阳率、伪阳率、阈值  \n",
    "auc_rfc = metrics.auc(fpr_rfc,tpr_rfc)                             # AUC得分\n",
    "score_rfc = metrics.accuracy_score(y_test,y_pred)                  # 模型准确率\n",
    "print([score_rfc,auc_rfc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05408032 -0.06239182 -0.28555694 ...  0.16912512 -0.05163623\n",
      "  0.27928096]\n"
     ]
    }
   ],
   "source": [
    "for column in im.columns:\n",
    "    print(im[column].values)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home/zhangqibin/anaconda3/envs/causal/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = CustomDataset(im.T.values, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_rate=0.8):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        # self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        # x = self.bn1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, epochs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(dataloader):.4f}\")\n",
    "\n",
    "    print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "    \n",
    "    validation_loss = running_loss / len(dataloader)\n",
    "    accuracy = total_correct / total_samples\n",
    "    \n",
    "    return validation_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5652173913043478 0.6521739130434783\n",
      "10 0.5869565217391305 0.6902173913043478\n",
      "20 0.6086956521739131 0.7228260869565217\n",
      "25 0.6304347826086957 0.7445652173913043\n",
      "30 0.6956521739130435 0.75\n",
      "40 0.717391304347826 0.7554347826086957\n",
      "50 0.7391304347826086 0.7554347826086957\n",
      "60 0.7608695652173914 0.7663043478260869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have the following variables:\n",
    "# features: Your feature dataframe with shape [#genes, #samples]\n",
    "# labels: Your binary label list with length #samples\n",
    "# input_dim: Number of input features\n",
    "# hidden_dim: Number of units in the hidden layer\n",
    "# output_dim: Number of classes (e.g., 2 for binary classification)\n",
    "\n",
    "# Create custom datasets for train, test, and validation\n",
    "train_dataset = CustomDataset(X_train, y_train.values)\n",
    "test_dataset = CustomDataset(X_test, y_test.values)\n",
    "\n",
    "# Create a data loader\n",
    "batch_size = 64  # You can adjust this according to your dataset size and available memory\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create an instance of the MLP model\n",
    "input_dim = 50\n",
    "hidden_dim = 64\n",
    "output_dim = 2\n",
    "model = MLP(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.4, 0.5]).to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "epochs = 300  # You can adjust the number of epochs as needed\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "best_acc_val = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(dataloader):.4f}\")\n",
    "    if epoch % 5 == 0:\n",
    "        _, val_acc = validate(model, DataLoader(test_dataset, batch_size=batch_size, shuffle=True), criterion)\n",
    "        if val_acc > best_acc_val:\n",
    "            best_acc_val = val_acc\n",
    "            _, train_acc = validate(model, dataloader, criterion)\n",
    "            print(epoch, best_acc_val, train_acc)\n",
    "            torch.save(model.state_dict(), './params/immune_mlp.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6522)"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "for _, y in train_dataset:\n",
    "    sum+=y\n",
    "1-sum/len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3375231722990672, 0.842391304347826)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model, DataLoader(train_dataset, batch_size=batch_size, shuffle=True), criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5652)"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "for _, y in test_dataset:\n",
    "    sum+=y\n",
    "1-sum/len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6313046216964722, 0.6956521739130435)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model, DataLoader(test_dataset, batch_size=batch_size, shuffle=True), criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use all genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have the following variables:\n",
    "# features: Your feature dataframe with shape [#genes, #samples]\n",
    "# labels: Your binary label list with length #samples\n",
    "# input_dim: Number of input features\n",
    "# hidden_dim: Number of units in the hidden layer\n",
    "# output_dim: Number of classes (e.g., 2 for binary classification)\n",
    "\n",
    "X_select_train, X_select_test, y_select_train, y_select_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create custom datasets for train, test, and validation\n",
    "train_dataset = CustomDataset(X_select_train, y_select_train.values)\n",
    "test_dataset = CustomDataset(X_select_test, y_select_test.values)\n",
    "\n",
    "# Create a data loader\n",
    "batch_size = 64  # You can adjust this according to your dataset size and available memory\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800, Loss: 0.7195\n",
      "Epoch 2/800, Loss: 0.7233\n",
      "Epoch 3/800, Loss: 0.7216\n",
      "Epoch 4/800, Loss: 0.7218\n",
      "Epoch 5/800, Loss: 0.6457\n",
      "Epoch 6/800, Loss: 0.6614\n",
      "Epoch 7/800, Loss: 0.6352\n",
      "Epoch 8/800, Loss: 0.6594\n",
      "Epoch 9/800, Loss: 0.6276\n",
      "Epoch 10/800, Loss: 0.6635\n",
      "Epoch 11/800, Loss: 0.6851\n",
      "Epoch 12/800, Loss: 0.6583\n",
      "Epoch 13/800, Loss: 0.6891\n",
      "Epoch 14/800, Loss: 0.6640\n",
      "Epoch 15/800, Loss: 0.6617\n",
      "Epoch 16/800, Loss: 0.6603\n",
      "Epoch 17/800, Loss: 0.6301\n",
      "Epoch 18/800, Loss: 0.6388\n",
      "Epoch 19/800, Loss: 0.6814\n",
      "Epoch 20/800, Loss: 0.6655\n",
      "Epoch 21/800, Loss: 0.6496\n",
      "Epoch 22/800, Loss: 0.6967\n",
      "Epoch 23/800, Loss: 0.6326\n",
      "Epoch 24/800, Loss: 0.6448\n",
      "Epoch 25/800, Loss: 0.6264\n",
      "Epoch 26/800, Loss: 0.6861\n",
      "Epoch 27/800, Loss: 0.6151\n",
      "Epoch 28/800, Loss: 0.6890\n",
      "Epoch 29/800, Loss: 0.6395\n",
      "Epoch 30/800, Loss: 0.6561\n",
      "Epoch 31/800, Loss: 0.6440\n",
      "Epoch 32/800, Loss: 0.6242\n",
      "Epoch 33/800, Loss: 0.6361\n",
      "Epoch 34/800, Loss: 0.6347\n",
      "Epoch 35/800, Loss: 0.6277\n",
      "Epoch 36/800, Loss: 0.6394\n",
      "Epoch 37/800, Loss: 0.6327\n",
      "Epoch 38/800, Loss: 0.6338\n",
      "Epoch 39/800, Loss: 0.6450\n",
      "Epoch 40/800, Loss: 0.6519\n",
      "Epoch 41/800, Loss: 0.6083\n",
      "Epoch 42/800, Loss: 0.6468\n",
      "Epoch 43/800, Loss: 0.6677\n",
      "Epoch 44/800, Loss: 0.6557\n",
      "Epoch 45/800, Loss: 0.6110\n",
      "Epoch 46/800, Loss: 0.6353\n",
      "Epoch 47/800, Loss: 0.6249\n",
      "Epoch 48/800, Loss: 0.6324\n",
      "Epoch 49/800, Loss: 0.6407\n",
      "Epoch 50/800, Loss: 0.6575\n",
      "Epoch 51/800, Loss: 0.6093\n",
      "Epoch 52/800, Loss: 0.6393\n",
      "Epoch 53/800, Loss: 0.6128\n",
      "Epoch 54/800, Loss: 0.6161\n",
      "Epoch 55/800, Loss: 0.5910\n",
      "Epoch 56/800, Loss: 0.6506\n",
      "Epoch 57/800, Loss: 0.6494\n",
      "Epoch 58/800, Loss: 0.6159\n",
      "Epoch 59/800, Loss: 0.6573\n",
      "Epoch 60/800, Loss: 0.6240\n",
      "Epoch 61/800, Loss: 0.5842\n",
      "Epoch 62/800, Loss: 0.6183\n",
      "Epoch 63/800, Loss: 0.6098\n",
      "Epoch 64/800, Loss: 0.6173\n",
      "Epoch 65/800, Loss: 0.6165\n",
      "Epoch 66/800, Loss: 0.5920\n",
      "Epoch 67/800, Loss: 0.6212\n",
      "Epoch 68/800, Loss: 0.5998\n",
      "Epoch 69/800, Loss: 0.6093\n",
      "Epoch 70/800, Loss: 0.5934\n",
      "Epoch 71/800, Loss: 0.6093\n",
      "Epoch 72/800, Loss: 0.5731\n",
      "Epoch 73/800, Loss: 0.6156\n",
      "Epoch 74/800, Loss: 0.6281\n",
      "Epoch 75/800, Loss: 0.6153\n",
      "Epoch 76/800, Loss: 0.6114\n",
      "Epoch 77/800, Loss: 0.5853\n",
      "Epoch 78/800, Loss: 0.6092\n",
      "Epoch 79/800, Loss: 0.6216\n",
      "Epoch 80/800, Loss: 0.6053\n",
      "Epoch 81/800, Loss: 0.6095\n",
      "Epoch 82/800, Loss: 0.6314\n",
      "Epoch 83/800, Loss: 0.5864\n",
      "Epoch 84/800, Loss: 0.6093\n",
      "Epoch 85/800, Loss: 0.5787\n",
      "Epoch 86/800, Loss: 0.5974\n",
      "Epoch 87/800, Loss: 0.6079\n",
      "Epoch 88/800, Loss: 0.6476\n",
      "Epoch 89/800, Loss: 0.5567\n",
      "Epoch 90/800, Loss: 0.5977\n",
      "Epoch 91/800, Loss: 0.6316\n",
      "Epoch 92/800, Loss: 0.6060\n",
      "Epoch 93/800, Loss: 0.5910\n",
      "Epoch 94/800, Loss: 0.6053\n",
      "Epoch 95/800, Loss: 0.5926\n",
      "Epoch 96/800, Loss: 0.5751\n",
      "Epoch 97/800, Loss: 0.6033\n",
      "Epoch 98/800, Loss: 0.5716\n",
      "Epoch 99/800, Loss: 0.5824\n",
      "Epoch 100/800, Loss: 0.6010\n",
      "Epoch 101/800, Loss: 0.5889\n",
      "Epoch 102/800, Loss: 0.5796\n",
      "Epoch 103/800, Loss: 0.5791\n",
      "Epoch 104/800, Loss: 0.5891\n",
      "Epoch 105/800, Loss: 0.5512\n",
      "Epoch 106/800, Loss: 0.5869\n",
      "Epoch 107/800, Loss: 0.6032\n",
      "Epoch 108/800, Loss: 0.5888\n",
      "Epoch 109/800, Loss: 0.6141\n",
      "Epoch 110/800, Loss: 0.6100\n",
      "Epoch 111/800, Loss: 0.5449\n",
      "Epoch 112/800, Loss: 0.5755\n",
      "Epoch 113/800, Loss: 0.5786\n",
      "Epoch 114/800, Loss: 0.5585\n",
      "Epoch 115/800, Loss: 0.6116\n",
      "Epoch 116/800, Loss: 0.5994\n",
      "Epoch 117/800, Loss: 0.5715\n",
      "Epoch 118/800, Loss: 0.5892\n",
      "Epoch 119/800, Loss: 0.5731\n",
      "Epoch 120/800, Loss: 0.5815\n",
      "Epoch 121/800, Loss: 0.5686\n",
      "Epoch 122/800, Loss: 0.5640\n",
      "Epoch 123/800, Loss: 0.5226\n",
      "Epoch 124/800, Loss: 0.5791\n",
      "Epoch 125/800, Loss: 0.5615\n",
      "Epoch 126/800, Loss: 0.5614\n",
      "Epoch 127/800, Loss: 0.6194\n",
      "Epoch 128/800, Loss: 0.5926\n",
      "Epoch 129/800, Loss: 0.5626\n",
      "Epoch 130/800, Loss: 0.5940\n",
      "Epoch 131/800, Loss: 0.5722\n",
      "Epoch 132/800, Loss: 0.5755\n",
      "Epoch 133/800, Loss: 0.5814\n",
      "Epoch 134/800, Loss: 0.5977\n",
      "Epoch 135/800, Loss: 0.5360\n",
      "Epoch 136/800, Loss: 0.6043\n",
      "Epoch 137/800, Loss: 0.5623\n",
      "Epoch 138/800, Loss: 0.5684\n",
      "Epoch 139/800, Loss: 0.5430\n",
      "Epoch 140/800, Loss: 0.5479\n",
      "Epoch 141/800, Loss: 0.5298\n",
      "Epoch 142/800, Loss: 0.5313\n",
      "Epoch 143/800, Loss: 0.6069\n",
      "Epoch 144/800, Loss: 0.5528\n",
      "Epoch 145/800, Loss: 0.5799\n",
      "Epoch 146/800, Loss: 0.5794\n",
      "Epoch 147/800, Loss: 0.5288\n",
      "Epoch 148/800, Loss: 0.5435\n",
      "Epoch 149/800, Loss: 0.5463\n",
      "Epoch 150/800, Loss: 0.5920\n",
      "Epoch 151/800, Loss: 0.5245\n",
      "Epoch 152/800, Loss: 0.5543\n",
      "Epoch 153/800, Loss: 0.6308\n",
      "Epoch 154/800, Loss: 0.6177\n",
      "Epoch 155/800, Loss: 0.5329\n",
      "Epoch 156/800, Loss: 0.5591\n",
      "Epoch 157/800, Loss: 0.5589\n",
      "Epoch 158/800, Loss: 0.5462\n",
      "Epoch 159/800, Loss: 0.5563\n",
      "Epoch 160/800, Loss: 0.5788\n",
      "Epoch 161/800, Loss: 0.5686\n",
      "Epoch 162/800, Loss: 0.5338\n",
      "Epoch 163/800, Loss: 0.5573\n",
      "Epoch 164/800, Loss: 0.5352\n",
      "Epoch 165/800, Loss: 0.5226\n",
      "Epoch 166/800, Loss: 0.5379\n",
      "Epoch 167/800, Loss: 0.5385\n",
      "Epoch 168/800, Loss: 0.5885\n",
      "Epoch 169/800, Loss: 0.5565\n",
      "Epoch 170/800, Loss: 0.5549\n",
      "Epoch 171/800, Loss: 0.5540\n",
      "Epoch 172/800, Loss: 0.5366\n",
      "Epoch 173/800, Loss: 0.5772\n",
      "Epoch 174/800, Loss: 0.6026\n",
      "Epoch 175/800, Loss: 0.5321\n",
      "Epoch 176/800, Loss: 0.5182\n",
      "Epoch 177/800, Loss: 0.5468\n",
      "Epoch 178/800, Loss: 0.5354\n",
      "Epoch 179/800, Loss: 0.5354\n",
      "Epoch 180/800, Loss: 0.5376\n",
      "Epoch 181/800, Loss: 0.5542\n",
      "Epoch 182/800, Loss: 0.5482\n",
      "Epoch 183/800, Loss: 0.5488\n",
      "Epoch 184/800, Loss: 0.5353\n",
      "Epoch 185/800, Loss: 0.5095\n",
      "Epoch 186/800, Loss: 0.5325\n",
      "Epoch 187/800, Loss: 0.5358\n",
      "Epoch 188/800, Loss: 0.5205\n",
      "Epoch 189/800, Loss: 0.5152\n",
      "Epoch 190/800, Loss: 0.5647\n",
      "Epoch 191/800, Loss: 0.5109\n",
      "Epoch 192/800, Loss: 0.4977\n",
      "Epoch 193/800, Loss: 0.5037\n",
      "Epoch 194/800, Loss: 0.5282\n",
      "Epoch 195/800, Loss: 0.5254\n",
      "Epoch 196/800, Loss: 0.5299\n",
      "Epoch 197/800, Loss: 0.5475\n",
      "Epoch 198/800, Loss: 0.5191\n",
      "Epoch 199/800, Loss: 0.5199\n",
      "Epoch 200/800, Loss: 0.5200\n",
      "Epoch 201/800, Loss: 0.5081\n",
      "Epoch 202/800, Loss: 0.5074\n",
      "Epoch 203/800, Loss: 0.4991\n",
      "Epoch 204/800, Loss: 0.5362\n",
      "Epoch 205/800, Loss: 0.5522\n",
      "Epoch 206/800, Loss: 0.5419\n",
      "Epoch 207/800, Loss: 0.5323\n",
      "Epoch 208/800, Loss: 0.5712\n",
      "Epoch 209/800, Loss: 0.5823\n",
      "Epoch 210/800, Loss: 0.5218\n",
      "Epoch 211/800, Loss: 0.5264\n",
      "Epoch 212/800, Loss: 0.5406\n",
      "Epoch 213/800, Loss: 0.5318\n",
      "Epoch 214/800, Loss: 0.5252\n",
      "Epoch 215/800, Loss: 0.5329\n",
      "Epoch 216/800, Loss: 0.5298\n",
      "Epoch 217/800, Loss: 0.5453\n",
      "Epoch 218/800, Loss: 0.5470\n",
      "Epoch 219/800, Loss: 0.5085\n",
      "Epoch 220/800, Loss: 0.5345\n",
      "Epoch 221/800, Loss: 0.5255\n",
      "Epoch 222/800, Loss: 0.5079\n",
      "Epoch 223/800, Loss: 0.5256\n",
      "Epoch 224/800, Loss: 0.5403\n",
      "Epoch 225/800, Loss: 0.5203\n",
      "Epoch 226/800, Loss: 0.5008\n",
      "Epoch 227/800, Loss: 0.5337\n",
      "Epoch 228/800, Loss: 0.5204\n",
      "Epoch 229/800, Loss: 0.5174\n",
      "Epoch 230/800, Loss: 0.5195\n",
      "Epoch 231/800, Loss: 0.4887\n",
      "Epoch 232/800, Loss: 0.5294\n",
      "Epoch 233/800, Loss: 0.4994\n",
      "Epoch 234/800, Loss: 0.5260\n",
      "Epoch 235/800, Loss: 0.5373\n",
      "Epoch 236/800, Loss: 0.4974\n",
      "Epoch 237/800, Loss: 0.5167\n",
      "Epoch 238/800, Loss: 0.5152\n",
      "Epoch 239/800, Loss: 0.5301\n",
      "Epoch 240/800, Loss: 0.5530\n",
      "Epoch 241/800, Loss: 0.5065\n",
      "Epoch 242/800, Loss: 0.5390\n",
      "Epoch 243/800, Loss: 0.5076\n",
      "Epoch 244/800, Loss: 0.5062\n",
      "Epoch 245/800, Loss: 0.5546\n",
      "Epoch 246/800, Loss: 0.5244\n",
      "Epoch 247/800, Loss: 0.5038\n",
      "Epoch 248/800, Loss: 0.4975\n",
      "Epoch 249/800, Loss: 0.5049\n",
      "Epoch 250/800, Loss: 0.5008\n",
      "Epoch 251/800, Loss: 0.4920\n",
      "Epoch 252/800, Loss: 0.4917\n",
      "Epoch 253/800, Loss: 0.5016\n",
      "Epoch 254/800, Loss: 0.5317\n",
      "Epoch 255/800, Loss: 0.4730\n",
      "Epoch 256/800, Loss: 0.5126\n",
      "Epoch 257/800, Loss: 0.4690\n",
      "Epoch 258/800, Loss: 0.5235\n",
      "Epoch 259/800, Loss: 0.4714\n",
      "Epoch 260/800, Loss: 0.4782\n",
      "Epoch 261/800, Loss: 0.5419\n",
      "Epoch 262/800, Loss: 0.4917\n",
      "Epoch 263/800, Loss: 0.5223\n",
      "Epoch 264/800, Loss: 0.5437\n",
      "Epoch 265/800, Loss: 0.4680\n",
      "Epoch 266/800, Loss: 0.5124\n",
      "Epoch 267/800, Loss: 0.5057\n",
      "Epoch 268/800, Loss: 0.5186\n",
      "Epoch 269/800, Loss: 0.5106\n",
      "Epoch 270/800, Loss: 0.5123\n",
      "Epoch 271/800, Loss: 0.4919\n",
      "Epoch 272/800, Loss: 0.5492\n",
      "Epoch 273/800, Loss: 0.4832\n",
      "Epoch 274/800, Loss: 0.4630\n",
      "Epoch 275/800, Loss: 0.4965\n",
      "Epoch 276/800, Loss: 0.5148\n",
      "Epoch 277/800, Loss: 0.4766\n",
      "Epoch 278/800, Loss: 0.5127\n",
      "Epoch 279/800, Loss: 0.4694\n",
      "Epoch 280/800, Loss: 0.4765\n",
      "Epoch 281/800, Loss: 0.4662\n",
      "Epoch 282/800, Loss: 0.4624\n",
      "Epoch 283/800, Loss: 0.4564\n",
      "Epoch 284/800, Loss: 0.4889\n",
      "Epoch 285/800, Loss: 0.4884\n",
      "Epoch 286/800, Loss: 0.5147\n",
      "Epoch 287/800, Loss: 0.5014\n",
      "Epoch 288/800, Loss: 0.4694\n",
      "Epoch 289/800, Loss: 0.4869\n",
      "Epoch 290/800, Loss: 0.4765\n",
      "Epoch 291/800, Loss: 0.4615\n",
      "Epoch 292/800, Loss: 0.4727\n",
      "Epoch 293/800, Loss: 0.4617\n",
      "Epoch 294/800, Loss: 0.4921\n",
      "Epoch 295/800, Loss: 0.4827\n",
      "Epoch 296/800, Loss: 0.4609\n",
      "Epoch 297/800, Loss: 0.4543\n",
      "Epoch 298/800, Loss: 0.4604\n",
      "Epoch 299/800, Loss: 0.4645\n",
      "Epoch 300/800, Loss: 0.4952\n",
      "Epoch 301/800, Loss: 0.4631\n",
      "Epoch 302/800, Loss: 0.4821\n",
      "Epoch 303/800, Loss: 0.4367\n",
      "Epoch 304/800, Loss: 0.4822\n",
      "Epoch 305/800, Loss: 0.4464\n",
      "Epoch 306/800, Loss: 0.4722\n",
      "Epoch 307/800, Loss: 0.4703\n",
      "Epoch 308/800, Loss: 0.4836\n",
      "Epoch 309/800, Loss: 0.4480\n",
      "Epoch 310/800, Loss: 0.4406\n",
      "Epoch 311/800, Loss: 0.4646\n",
      "Epoch 312/800, Loss: 0.4801\n",
      "Epoch 313/800, Loss: 0.4724\n",
      "Epoch 314/800, Loss: 0.4611\n",
      "Epoch 315/800, Loss: 0.4702\n",
      "Epoch 316/800, Loss: 0.4548\n",
      "Epoch 317/800, Loss: 0.4810\n",
      "Epoch 318/800, Loss: 0.4760\n",
      "Epoch 319/800, Loss: 0.4860\n",
      "Epoch 320/800, Loss: 0.4546\n",
      "Epoch 321/800, Loss: 0.4730\n",
      "Epoch 322/800, Loss: 0.4749\n",
      "Epoch 323/800, Loss: 0.4963\n",
      "Epoch 324/800, Loss: 0.4313\n",
      "Epoch 325/800, Loss: 0.4675\n",
      "Epoch 326/800, Loss: 0.4593\n",
      "Epoch 327/800, Loss: 0.4562\n",
      "Epoch 328/800, Loss: 0.4591\n",
      "Epoch 329/800, Loss: 0.4342\n",
      "Epoch 330/800, Loss: 0.4662\n",
      "Epoch 331/800, Loss: 0.4758\n",
      "Epoch 332/800, Loss: 0.4592\n",
      "Epoch 333/800, Loss: 0.4551\n",
      "Epoch 334/800, Loss: 0.4604\n",
      "Epoch 335/800, Loss: 0.4683\n",
      "Epoch 336/800, Loss: 0.4942\n",
      "Epoch 337/800, Loss: 0.4373\n",
      "Epoch 338/800, Loss: 0.4668\n",
      "Epoch 339/800, Loss: 0.4468\n",
      "Epoch 340/800, Loss: 0.4553\n",
      "Epoch 341/800, Loss: 0.4844\n",
      "Epoch 342/800, Loss: 0.4576\n",
      "Epoch 343/800, Loss: 0.4877\n",
      "Epoch 344/800, Loss: 0.4325\n",
      "Epoch 345/800, Loss: 0.4700\n",
      "Epoch 346/800, Loss: 0.4562\n",
      "Epoch 347/800, Loss: 0.4640\n",
      "Epoch 348/800, Loss: 0.4541\n",
      "Epoch 349/800, Loss: 0.4116\n",
      "Epoch 350/800, Loss: 0.4402\n",
      "Epoch 351/800, Loss: 0.4574\n",
      "Epoch 352/800, Loss: 0.4639\n",
      "Epoch 353/800, Loss: 0.4226\n",
      "Epoch 354/800, Loss: 0.4548\n",
      "Epoch 355/800, Loss: 0.5177\n",
      "Epoch 356/800, Loss: 0.4393\n",
      "Epoch 357/800, Loss: 0.4001\n",
      "Epoch 358/800, Loss: 0.4681\n",
      "Epoch 359/800, Loss: 0.4385\n",
      "Epoch 360/800, Loss: 0.5043\n",
      "Epoch 361/800, Loss: 0.4461\n",
      "Epoch 362/800, Loss: 0.4799\n",
      "Epoch 363/800, Loss: 0.4566\n",
      "Epoch 364/800, Loss: 0.4732\n",
      "Epoch 365/800, Loss: 0.4691\n",
      "Epoch 366/800, Loss: 0.4629\n",
      "Epoch 367/800, Loss: 0.4273\n",
      "Epoch 368/800, Loss: 0.4560\n",
      "Epoch 369/800, Loss: 0.4377\n",
      "Epoch 370/800, Loss: 0.4723\n",
      "Epoch 371/800, Loss: 0.4851\n",
      "Epoch 372/800, Loss: 0.4416\n",
      "Epoch 373/800, Loss: 0.4660\n",
      "Epoch 374/800, Loss: 0.4433\n",
      "Epoch 375/800, Loss: 0.4407\n",
      "Epoch 376/800, Loss: 0.4291\n",
      "Epoch 377/800, Loss: 0.4282\n",
      "Epoch 378/800, Loss: 0.4323\n",
      "Epoch 379/800, Loss: 0.4563\n",
      "Epoch 380/800, Loss: 0.4631\n",
      "Epoch 381/800, Loss: 0.4549\n",
      "Epoch 382/800, Loss: 0.4216\n",
      "Epoch 383/800, Loss: 0.4708\n",
      "Epoch 384/800, Loss: 0.4352\n",
      "Epoch 385/800, Loss: 0.4460\n",
      "Epoch 386/800, Loss: 0.4378\n",
      "Epoch 387/800, Loss: 0.4428\n",
      "Epoch 388/800, Loss: 0.4048\n",
      "Epoch 389/800, Loss: 0.4067\n",
      "Epoch 390/800, Loss: 0.4546\n",
      "Epoch 391/800, Loss: 0.4317\n",
      "Epoch 392/800, Loss: 0.4339\n",
      "Epoch 393/800, Loss: 0.4434\n",
      "Epoch 394/800, Loss: 0.4363\n",
      "Epoch 395/800, Loss: 0.4409\n",
      "Epoch 396/800, Loss: 0.4258\n",
      "Epoch 397/800, Loss: 0.4274\n",
      "Epoch 398/800, Loss: 0.4414\n",
      "Epoch 399/800, Loss: 0.4595\n",
      "Epoch 400/800, Loss: 0.4200\n",
      "Epoch 401/800, Loss: 0.4048\n",
      "Epoch 402/800, Loss: 0.4020\n",
      "Epoch 403/800, Loss: 0.4287\n",
      "Epoch 404/800, Loss: 0.4228\n",
      "Epoch 405/800, Loss: 0.4134\n",
      "Epoch 406/800, Loss: 0.4482\n",
      "Epoch 407/800, Loss: 0.4384\n",
      "Epoch 408/800, Loss: 0.4490\n",
      "Epoch 409/800, Loss: 0.4433\n",
      "Epoch 410/800, Loss: 0.4230\n",
      "Epoch 411/800, Loss: 0.4858\n",
      "Epoch 412/800, Loss: 0.4453\n",
      "Epoch 413/800, Loss: 0.4573\n",
      "Epoch 414/800, Loss: 0.4552\n",
      "Epoch 415/800, Loss: 0.4262\n",
      "Epoch 416/800, Loss: 0.4238\n",
      "Epoch 417/800, Loss: 0.4128\n",
      "Epoch 418/800, Loss: 0.4475\n",
      "Epoch 419/800, Loss: 0.4754\n",
      "Epoch 420/800, Loss: 0.4363\n",
      "Epoch 421/800, Loss: 0.4151\n",
      "Epoch 422/800, Loss: 0.4164\n",
      "Epoch 423/800, Loss: 0.4385\n",
      "Epoch 424/800, Loss: 0.4553\n",
      "Epoch 425/800, Loss: 0.4449\n",
      "Epoch 426/800, Loss: 0.4121\n",
      "Epoch 427/800, Loss: 0.4083\n",
      "Epoch 428/800, Loss: 0.4146\n",
      "Epoch 429/800, Loss: 0.4063\n",
      "Epoch 430/800, Loss: 0.4314\n",
      "Epoch 431/800, Loss: 0.4156\n",
      "Epoch 432/800, Loss: 0.4360\n",
      "Epoch 433/800, Loss: 0.4048\n",
      "Epoch 434/800, Loss: 0.4680\n",
      "Epoch 435/800, Loss: 0.4148\n",
      "Epoch 436/800, Loss: 0.4235\n",
      "Epoch 437/800, Loss: 0.4424\n",
      "Epoch 438/800, Loss: 0.4222\n",
      "Epoch 439/800, Loss: 0.4146\n",
      "Epoch 440/800, Loss: 0.4202\n",
      "Epoch 441/800, Loss: 0.4558\n",
      "Epoch 442/800, Loss: 0.4658\n",
      "Epoch 443/800, Loss: 0.3983\n",
      "Epoch 444/800, Loss: 0.4631\n",
      "Epoch 445/800, Loss: 0.4059\n",
      "Epoch 446/800, Loss: 0.3800\n",
      "Epoch 447/800, Loss: 0.3983\n",
      "Epoch 448/800, Loss: 0.3795\n",
      "Epoch 449/800, Loss: 0.4170\n",
      "Epoch 450/800, Loss: 0.4198\n",
      "Epoch 451/800, Loss: 0.4380\n",
      "Epoch 452/800, Loss: 0.3934\n",
      "Epoch 453/800, Loss: 0.4343\n",
      "Epoch 454/800, Loss: 0.4185\n",
      "Epoch 455/800, Loss: 0.4029\n",
      "Epoch 456/800, Loss: 0.4037\n",
      "Epoch 457/800, Loss: 0.4174\n",
      "Epoch 458/800, Loss: 0.4140\n",
      "Epoch 459/800, Loss: 0.3946\n",
      "Epoch 460/800, Loss: 0.4320\n",
      "Epoch 461/800, Loss: 0.4207\n",
      "Epoch 462/800, Loss: 0.4904\n",
      "Epoch 463/800, Loss: 0.4029\n",
      "Epoch 464/800, Loss: 0.4742\n",
      "Epoch 465/800, Loss: 0.3900\n",
      "Epoch 466/800, Loss: 0.4617\n",
      "Epoch 467/800, Loss: 0.4440\n",
      "Epoch 468/800, Loss: 0.4012\n",
      "Epoch 469/800, Loss: 0.4063\n",
      "Epoch 470/800, Loss: 0.4403\n",
      "Epoch 471/800, Loss: 0.4109\n",
      "Epoch 472/800, Loss: 0.4405\n",
      "Epoch 473/800, Loss: 0.4356\n",
      "Epoch 474/800, Loss: 0.4107\n",
      "Epoch 475/800, Loss: 0.4428\n",
      "Epoch 476/800, Loss: 0.3910\n",
      "Epoch 477/800, Loss: 0.4395\n",
      "Epoch 478/800, Loss: 0.3767\n",
      "Epoch 479/800, Loss: 0.4267\n",
      "Epoch 480/800, Loss: 0.4016\n",
      "Epoch 481/800, Loss: 0.4610\n",
      "Epoch 482/800, Loss: 0.4307\n",
      "Epoch 483/800, Loss: 0.4511\n",
      "Epoch 484/800, Loss: 0.4199\n",
      "Epoch 485/800, Loss: 0.4542\n",
      "Epoch 486/800, Loss: 0.4512\n",
      "Epoch 487/800, Loss: 0.4236\n",
      "Epoch 488/800, Loss: 0.4301\n",
      "Epoch 489/800, Loss: 0.4111\n",
      "Epoch 490/800, Loss: 0.4220\n",
      "Epoch 491/800, Loss: 0.4117\n",
      "Epoch 492/800, Loss: 0.4242\n",
      "Epoch 493/800, Loss: 0.4129\n",
      "Epoch 494/800, Loss: 0.4216\n",
      "Epoch 495/800, Loss: 0.4305\n",
      "Epoch 496/800, Loss: 0.3893\n",
      "Epoch 497/800, Loss: 0.4034\n",
      "Epoch 498/800, Loss: 0.4194\n",
      "Epoch 499/800, Loss: 0.3822\n",
      "Epoch 500/800, Loss: 0.4362\n",
      "Epoch 501/800, Loss: 0.4033\n",
      "Epoch 502/800, Loss: 0.4314\n",
      "Epoch 503/800, Loss: 0.4225\n",
      "Epoch 504/800, Loss: 0.4268\n",
      "Epoch 505/800, Loss: 0.4122\n",
      "Epoch 506/800, Loss: 0.4467\n",
      "Epoch 507/800, Loss: 0.4556\n",
      "Epoch 508/800, Loss: 0.3974\n",
      "Epoch 509/800, Loss: 0.4204\n",
      "Epoch 510/800, Loss: 0.4361\n",
      "Epoch 511/800, Loss: 0.4159\n",
      "Epoch 512/800, Loss: 0.4090\n",
      "Epoch 513/800, Loss: 0.3972\n",
      "Epoch 514/800, Loss: 0.4111\n",
      "Epoch 515/800, Loss: 0.4067\n",
      "Epoch 516/800, Loss: 0.3845\n",
      "Epoch 517/800, Loss: 0.3875\n",
      "Epoch 518/800, Loss: 0.3935\n",
      "Epoch 519/800, Loss: 0.4320\n",
      "Epoch 520/800, Loss: 0.4383\n",
      "Epoch 521/800, Loss: 0.4059\n",
      "Epoch 522/800, Loss: 0.4043\n",
      "Epoch 523/800, Loss: 0.4045\n",
      "Epoch 524/800, Loss: 0.4251\n",
      "Epoch 525/800, Loss: 0.3930\n",
      "Epoch 526/800, Loss: 0.4423\n",
      "Epoch 527/800, Loss: 0.4203\n",
      "Epoch 528/800, Loss: 0.3742\n",
      "Epoch 529/800, Loss: 0.3716\n",
      "Epoch 530/800, Loss: 0.4319\n",
      "Epoch 531/800, Loss: 0.4104\n",
      "Epoch 532/800, Loss: 0.4075\n",
      "Epoch 533/800, Loss: 0.4419\n",
      "Epoch 534/800, Loss: 0.3854\n",
      "Epoch 535/800, Loss: 0.3962\n",
      "Epoch 536/800, Loss: 0.4370\n",
      "Epoch 537/800, Loss: 0.4571\n",
      "Epoch 538/800, Loss: 0.4329\n",
      "Epoch 539/800, Loss: 0.3919\n",
      "Epoch 540/800, Loss: 0.4350\n",
      "Epoch 541/800, Loss: 0.4124\n",
      "Epoch 542/800, Loss: 0.4176\n",
      "Epoch 543/800, Loss: 0.3781\n",
      "Epoch 544/800, Loss: 0.4363\n",
      "Epoch 545/800, Loss: 0.4086\n",
      "Epoch 546/800, Loss: 0.3830\n",
      "Epoch 547/800, Loss: 0.4323\n",
      "Epoch 548/800, Loss: 0.4009\n",
      "Epoch 549/800, Loss: 0.4366\n",
      "Epoch 550/800, Loss: 0.4099\n",
      "Epoch 551/800, Loss: 0.4353\n",
      "Epoch 552/800, Loss: 0.4389\n",
      "Epoch 553/800, Loss: 0.4436\n",
      "Epoch 554/800, Loss: 0.4272\n",
      "Epoch 555/800, Loss: 0.3904\n",
      "Epoch 556/800, Loss: 0.3634\n",
      "Epoch 557/800, Loss: 0.4437\n",
      "Epoch 558/800, Loss: 0.4247\n",
      "Epoch 559/800, Loss: 0.4478\n",
      "Epoch 560/800, Loss: 0.4148\n",
      "Epoch 561/800, Loss: 0.4206\n",
      "Epoch 562/800, Loss: 0.3822\n",
      "Epoch 563/800, Loss: 0.3736\n",
      "Epoch 564/800, Loss: 0.4017\n",
      "Epoch 565/800, Loss: 0.4197\n",
      "Epoch 566/800, Loss: 0.4239\n",
      "Epoch 567/800, Loss: 0.4188\n",
      "Epoch 568/800, Loss: 0.4240\n",
      "Epoch 569/800, Loss: 0.4412\n",
      "Epoch 570/800, Loss: 0.4108\n",
      "Epoch 571/800, Loss: 0.4057\n",
      "Epoch 572/800, Loss: 0.4038\n",
      "Epoch 573/800, Loss: 0.4188\n",
      "Epoch 574/800, Loss: 0.3911\n",
      "Epoch 575/800, Loss: 0.4348\n",
      "Epoch 576/800, Loss: 0.4115\n",
      "Epoch 577/800, Loss: 0.3795\n",
      "Epoch 578/800, Loss: 0.3948\n",
      "Epoch 579/800, Loss: 0.4177\n",
      "Epoch 580/800, Loss: 0.4245\n",
      "Epoch 581/800, Loss: 0.4330\n",
      "Epoch 582/800, Loss: 0.4180\n",
      "Epoch 583/800, Loss: 0.4075\n",
      "Epoch 584/800, Loss: 0.4367\n",
      "Epoch 585/800, Loss: 0.4092\n",
      "Epoch 586/800, Loss: 0.3915\n",
      "Epoch 587/800, Loss: 0.3626\n",
      "Epoch 588/800, Loss: 0.3957\n",
      "Epoch 589/800, Loss: 0.4145\n",
      "Epoch 590/800, Loss: 0.3996\n",
      "Epoch 591/800, Loss: 0.4372\n",
      "Epoch 592/800, Loss: 0.3899\n",
      "Epoch 593/800, Loss: 0.4057\n",
      "Epoch 594/800, Loss: 0.4031\n",
      "Epoch 595/800, Loss: 0.4042\n",
      "Epoch 596/800, Loss: 0.4024\n",
      "Epoch 597/800, Loss: 0.4277\n",
      "Epoch 598/800, Loss: 0.4488\n",
      "Epoch 599/800, Loss: 0.4006\n",
      "Epoch 600/800, Loss: 0.4717\n",
      "Epoch 601/800, Loss: 0.4067\n",
      "Epoch 602/800, Loss: 0.3831\n",
      "Epoch 603/800, Loss: 0.4137\n",
      "Epoch 604/800, Loss: 0.3899\n",
      "Epoch 605/800, Loss: 0.4385\n",
      "Epoch 606/800, Loss: 0.4394\n",
      "Epoch 607/800, Loss: 0.3910\n",
      "Epoch 608/800, Loss: 0.4521\n",
      "Epoch 609/800, Loss: 0.3565\n",
      "Epoch 610/800, Loss: 0.3700\n",
      "Epoch 611/800, Loss: 0.4167\n",
      "Epoch 612/800, Loss: 0.4660\n",
      "Epoch 613/800, Loss: 0.4357\n",
      "Epoch 614/800, Loss: 0.3982\n",
      "Epoch 615/800, Loss: 0.3921\n",
      "Epoch 616/800, Loss: 0.4272\n",
      "Epoch 617/800, Loss: 0.4144\n",
      "Epoch 618/800, Loss: 0.4023\n",
      "Epoch 619/800, Loss: 0.4410\n",
      "Epoch 620/800, Loss: 0.3920\n",
      "Epoch 621/800, Loss: 0.4246\n",
      "Epoch 622/800, Loss: 0.3823\n",
      "Epoch 623/800, Loss: 0.4261\n",
      "Epoch 624/800, Loss: 0.4072\n",
      "Epoch 625/800, Loss: 0.3925\n",
      "Epoch 626/800, Loss: 0.3944\n",
      "Epoch 627/800, Loss: 0.4065\n",
      "Epoch 628/800, Loss: 0.4212\n",
      "Epoch 629/800, Loss: 0.3860\n",
      "Epoch 630/800, Loss: 0.3525\n",
      "Epoch 631/800, Loss: 0.3816\n",
      "Epoch 632/800, Loss: 0.4197\n",
      "Epoch 633/800, Loss: 0.4278\n",
      "Epoch 634/800, Loss: 0.3938\n",
      "Epoch 635/800, Loss: 0.4213\n",
      "Epoch 636/800, Loss: 0.3933\n",
      "Epoch 637/800, Loss: 0.4026\n",
      "Epoch 638/800, Loss: 0.4286\n",
      "Epoch 639/800, Loss: 0.3834\n",
      "Epoch 640/800, Loss: 0.4592\n",
      "Epoch 641/800, Loss: 0.4337\n",
      "Epoch 642/800, Loss: 0.4248\n",
      "Epoch 643/800, Loss: 0.4215\n",
      "Epoch 644/800, Loss: 0.4138\n",
      "Epoch 645/800, Loss: 0.4173\n",
      "Epoch 646/800, Loss: 0.4250\n",
      "Epoch 647/800, Loss: 0.4350\n",
      "Epoch 648/800, Loss: 0.4236\n",
      "Epoch 649/800, Loss: 0.3710\n",
      "Epoch 650/800, Loss: 0.3921\n",
      "Epoch 651/800, Loss: 0.4162\n",
      "Epoch 652/800, Loss: 0.4098\n",
      "Epoch 653/800, Loss: 0.3873\n",
      "Epoch 654/800, Loss: 0.3918\n",
      "Epoch 655/800, Loss: 0.3745\n",
      "Epoch 656/800, Loss: 0.3981\n",
      "Epoch 657/800, Loss: 0.3934\n",
      "Epoch 658/800, Loss: 0.3910\n",
      "Epoch 659/800, Loss: 0.3547\n",
      "Epoch 660/800, Loss: 0.3656\n",
      "Epoch 661/800, Loss: 0.3974\n",
      "Epoch 662/800, Loss: 0.3910\n",
      "Epoch 663/800, Loss: 0.3968\n",
      "Epoch 664/800, Loss: 0.3911\n",
      "Epoch 665/800, Loss: 0.3898\n",
      "Epoch 666/800, Loss: 0.3837\n",
      "Epoch 667/800, Loss: 0.3922\n",
      "Epoch 668/800, Loss: 0.3930\n",
      "Epoch 669/800, Loss: 0.3785\n",
      "Epoch 670/800, Loss: 0.4153\n",
      "Epoch 671/800, Loss: 0.3816\n",
      "Epoch 672/800, Loss: 0.4218\n",
      "Epoch 673/800, Loss: 0.4170\n",
      "Epoch 674/800, Loss: 0.3680\n",
      "Epoch 675/800, Loss: 0.4173\n",
      "Epoch 676/800, Loss: 0.3944\n",
      "Epoch 677/800, Loss: 0.4111\n",
      "Epoch 678/800, Loss: 0.4210\n",
      "Epoch 679/800, Loss: 0.4065\n",
      "Epoch 680/800, Loss: 0.4017\n",
      "Epoch 681/800, Loss: 0.4099\n",
      "Epoch 682/800, Loss: 0.3462\n",
      "Epoch 683/800, Loss: 0.3780\n",
      "Epoch 684/800, Loss: 0.4010\n",
      "Epoch 685/800, Loss: 0.3751\n",
      "Epoch 686/800, Loss: 0.3994\n",
      "Epoch 687/800, Loss: 0.4091\n",
      "Epoch 688/800, Loss: 0.4044\n",
      "Epoch 689/800, Loss: 0.4063\n",
      "Epoch 690/800, Loss: 0.3840\n",
      "Epoch 691/800, Loss: 0.4173\n",
      "Epoch 692/800, Loss: 0.4091\n",
      "Epoch 693/800, Loss: 0.4071\n",
      "Epoch 694/800, Loss: 0.3952\n",
      "Epoch 695/800, Loss: 0.3815\n",
      "Epoch 696/800, Loss: 0.3966\n",
      "Epoch 697/800, Loss: 0.3943\n",
      "Epoch 698/800, Loss: 0.4132\n",
      "Epoch 699/800, Loss: 0.3667\n",
      "Epoch 700/800, Loss: 0.3951\n",
      "Epoch 701/800, Loss: 0.3826\n",
      "Epoch 702/800, Loss: 0.3767\n",
      "Epoch 703/800, Loss: 0.3771\n",
      "Epoch 704/800, Loss: 0.3903\n",
      "Epoch 705/800, Loss: 0.3592\n",
      "Epoch 706/800, Loss: 0.4214\n",
      "Epoch 707/800, Loss: 0.3879\n",
      "Epoch 708/800, Loss: 0.4315\n",
      "Epoch 709/800, Loss: 0.3472\n",
      "Epoch 710/800, Loss: 0.3776\n",
      "Epoch 711/800, Loss: 0.3835\n",
      "Epoch 712/800, Loss: 0.3980\n",
      "Epoch 713/800, Loss: 0.4101\n",
      "Epoch 714/800, Loss: 0.3943\n",
      "Epoch 715/800, Loss: 0.3888\n",
      "Epoch 716/800, Loss: 0.3850\n",
      "Epoch 717/800, Loss: 0.3981\n",
      "Epoch 718/800, Loss: 0.4079\n",
      "Epoch 719/800, Loss: 0.4203\n",
      "Epoch 720/800, Loss: 0.4023\n",
      "Epoch 721/800, Loss: 0.4146\n",
      "Epoch 722/800, Loss: 0.3824\n",
      "Epoch 723/800, Loss: 0.4277\n",
      "Epoch 724/800, Loss: 0.4179\n",
      "Epoch 725/800, Loss: 0.4226\n",
      "Epoch 726/800, Loss: 0.4015\n",
      "Epoch 727/800, Loss: 0.4028\n",
      "Epoch 728/800, Loss: 0.3901\n",
      "Epoch 729/800, Loss: 0.4248\n",
      "Epoch 730/800, Loss: 0.4099\n",
      "Epoch 731/800, Loss: 0.3767\n",
      "Epoch 732/800, Loss: 0.4323\n",
      "Epoch 733/800, Loss: 0.3807\n",
      "Epoch 734/800, Loss: 0.4133\n",
      "Epoch 735/800, Loss: 0.3744\n",
      "Epoch 736/800, Loss: 0.4034\n",
      "Epoch 737/800, Loss: 0.3617\n",
      "Epoch 738/800, Loss: 0.4137\n",
      "Epoch 739/800, Loss: 0.3720\n",
      "Epoch 740/800, Loss: 0.4043\n",
      "Epoch 741/800, Loss: 0.3755\n",
      "Epoch 742/800, Loss: 0.3882\n",
      "Epoch 743/800, Loss: 0.4078\n",
      "Epoch 744/800, Loss: 0.3907\n",
      "Epoch 745/800, Loss: 0.4294\n",
      "Epoch 746/800, Loss: 0.3893\n",
      "Epoch 747/800, Loss: 0.3736\n",
      "Epoch 748/800, Loss: 0.3921\n",
      "Epoch 749/800, Loss: 0.4162\n",
      "Epoch 750/800, Loss: 0.4029\n",
      "Epoch 751/800, Loss: 0.4272\n",
      "Epoch 752/800, Loss: 0.4009\n",
      "Epoch 753/800, Loss: 0.3975\n",
      "Epoch 754/800, Loss: 0.3646\n",
      "Epoch 755/800, Loss: 0.4251\n",
      "Epoch 756/800, Loss: 0.3838\n",
      "Epoch 757/800, Loss: 0.4040\n",
      "Epoch 758/800, Loss: 0.4528\n",
      "Epoch 759/800, Loss: 0.4194\n",
      "Epoch 760/800, Loss: 0.4076\n",
      "Epoch 761/800, Loss: 0.3804\n",
      "Epoch 762/800, Loss: 0.4006\n",
      "Epoch 763/800, Loss: 0.4300\n",
      "Epoch 764/800, Loss: 0.3732\n",
      "Epoch 765/800, Loss: 0.3782\n",
      "Epoch 766/800, Loss: 0.3892\n",
      "Epoch 767/800, Loss: 0.4111\n",
      "Epoch 768/800, Loss: 0.3767\n",
      "Epoch 769/800, Loss: 0.4478\n",
      "Epoch 770/800, Loss: 0.4314\n",
      "Epoch 771/800, Loss: 0.4170\n",
      "Epoch 772/800, Loss: 0.4170\n",
      "Epoch 773/800, Loss: 0.4007\n",
      "Epoch 774/800, Loss: 0.3802\n",
      "Epoch 775/800, Loss: 0.3947\n",
      "Epoch 776/800, Loss: 0.4087\n",
      "Epoch 777/800, Loss: 0.3710\n",
      "Epoch 778/800, Loss: 0.3832\n",
      "Epoch 779/800, Loss: 0.3917\n",
      "Epoch 780/800, Loss: 0.3500\n",
      "Epoch 781/800, Loss: 0.4085\n",
      "Epoch 782/800, Loss: 0.4272\n",
      "Epoch 783/800, Loss: 0.3762\n",
      "Epoch 784/800, Loss: 0.3814\n",
      "Epoch 785/800, Loss: 0.3470\n",
      "Epoch 786/800, Loss: 0.3527\n",
      "Epoch 787/800, Loss: 0.3983\n",
      "Epoch 788/800, Loss: 0.4027\n",
      "Epoch 789/800, Loss: 0.3991\n",
      "Epoch 790/800, Loss: 0.3973\n",
      "Epoch 791/800, Loss: 0.3795\n",
      "Epoch 792/800, Loss: 0.3865\n",
      "Epoch 793/800, Loss: 0.4112\n",
      "Epoch 794/800, Loss: 0.3669\n",
      "Epoch 795/800, Loss: 0.4079\n",
      "Epoch 796/800, Loss: 0.3903\n",
      "Epoch 797/800, Loss: 0.4027\n",
      "Epoch 798/800, Loss: 0.4224\n",
      "Epoch 799/800, Loss: 0.3834\n",
      "Epoch 800/800, Loss: 0.4135\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the MLP model\n",
    "input_dim = 1386\n",
    "hidden_dim = 128\n",
    "output_dim = 2\n",
    "model = MLP(input_dim, hidden_dim, output_dim, dropout_rate=0.95)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "epochs = 800  # You can adjust the number of epochs as needed\n",
    "train(model, dataloader, criterion, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.11729952444632848, 0.9945652173913043),\n",
       " (1.2277599573135376, 0.6304347826086957))"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model, DataLoader(train_dataset, batch_size=batch_size, shuffle=True), criterion), validate(model, DataLoader(test_dataset, batch_size=batch_size, shuffle=True), criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCGA-D3-A3CE</th>\n",
       "      <th>TCGA-D9-A6E9</th>\n",
       "      <th>TCGA-FR-A729</th>\n",
       "      <th>TCGA-D3-A3CF</th>\n",
       "      <th>TCGA-WE-AA9Y</th>\n",
       "      <th>TCGA-D3-A3CC</th>\n",
       "      <th>TCGA-Z2-AA3V</th>\n",
       "      <th>TCGA-GN-A8LL</th>\n",
       "      <th>TCGA-GN-A8LK</th>\n",
       "      <th>TCGA-FS-A1ZS</th>\n",
       "      <th>...</th>\n",
       "      <th>TCGA-EE-A2M5</th>\n",
       "      <th>TCGA-D3-A5GL</th>\n",
       "      <th>TCGA-EE-A2M7</th>\n",
       "      <th>TCGA-EE-A2M6</th>\n",
       "      <th>TCGA-D9-A3Z1</th>\n",
       "      <th>TCGA-D9-A3Z3</th>\n",
       "      <th>TCGA-EE-A3J7</th>\n",
       "      <th>TCGA-EE-A3AF</th>\n",
       "      <th>TCGA-EE-A2M8</th>\n",
       "      <th>TCGA-GF-A6C9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CSMD2</th>\n",
       "      <td>-0.054080</td>\n",
       "      <td>-0.229752</td>\n",
       "      <td>-0.195151</td>\n",
       "      <td>-0.127083</td>\n",
       "      <td>0.416151</td>\n",
       "      <td>-0.156377</td>\n",
       "      <td>-0.246390</td>\n",
       "      <td>-0.297175</td>\n",
       "      <td>-0.224577</td>\n",
       "      <td>14.230808</td>\n",
       "      <td>...</td>\n",
       "      <td>7.849712</td>\n",
       "      <td>-0.155544</td>\n",
       "      <td>-0.246903</td>\n",
       "      <td>-0.283339</td>\n",
       "      <td>-0.104239</td>\n",
       "      <td>-0.173656</td>\n",
       "      <td>-0.162199</td>\n",
       "      <td>-0.148308</td>\n",
       "      <td>-0.045141</td>\n",
       "      <td>0.433603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZC3H12D</th>\n",
       "      <td>-0.062392</td>\n",
       "      <td>0.787136</td>\n",
       "      <td>1.198162</td>\n",
       "      <td>0.525882</td>\n",
       "      <td>-0.155966</td>\n",
       "      <td>-0.346858</td>\n",
       "      <td>0.678543</td>\n",
       "      <td>-0.486661</td>\n",
       "      <td>-0.475804</td>\n",
       "      <td>-0.440953</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.401698</td>\n",
       "      <td>-0.484379</td>\n",
       "      <td>0.023117</td>\n",
       "      <td>-0.290790</td>\n",
       "      <td>0.175650</td>\n",
       "      <td>0.678512</td>\n",
       "      <td>-0.407778</td>\n",
       "      <td>-0.289600</td>\n",
       "      <td>1.769030</td>\n",
       "      <td>1.608189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KLF15</th>\n",
       "      <td>-0.285557</td>\n",
       "      <td>-0.925922</td>\n",
       "      <td>-0.094339</td>\n",
       "      <td>-0.945225</td>\n",
       "      <td>2.075588</td>\n",
       "      <td>0.052303</td>\n",
       "      <td>0.846139</td>\n",
       "      <td>1.212722</td>\n",
       "      <td>-0.419437</td>\n",
       "      <td>-1.190301</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.198349</td>\n",
       "      <td>-0.739588</td>\n",
       "      <td>0.785233</td>\n",
       "      <td>-0.075452</td>\n",
       "      <td>-0.838268</td>\n",
       "      <td>-0.032067</td>\n",
       "      <td>3.523628</td>\n",
       "      <td>0.981693</td>\n",
       "      <td>-0.790780</td>\n",
       "      <td>-0.560695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRPL30</th>\n",
       "      <td>-1.103459</td>\n",
       "      <td>0.292058</td>\n",
       "      <td>1.357681</td>\n",
       "      <td>1.485900</td>\n",
       "      <td>0.622276</td>\n",
       "      <td>-0.069789</td>\n",
       "      <td>-1.869262</td>\n",
       "      <td>-0.388936</td>\n",
       "      <td>-0.312104</td>\n",
       "      <td>-0.999960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062576</td>\n",
       "      <td>0.304411</td>\n",
       "      <td>-0.620333</td>\n",
       "      <td>2.073774</td>\n",
       "      <td>0.047338</td>\n",
       "      <td>-1.527091</td>\n",
       "      <td>-0.306298</td>\n",
       "      <td>-1.364359</td>\n",
       "      <td>-0.513214</td>\n",
       "      <td>-0.786474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UCK1</th>\n",
       "      <td>-0.566261</td>\n",
       "      <td>0.194461</td>\n",
       "      <td>-0.750406</td>\n",
       "      <td>0.675687</td>\n",
       "      <td>0.012524</td>\n",
       "      <td>-0.675303</td>\n",
       "      <td>4.375373</td>\n",
       "      <td>1.203905</td>\n",
       "      <td>2.453245</td>\n",
       "      <td>-1.252481</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.632063</td>\n",
       "      <td>-0.559619</td>\n",
       "      <td>-0.579764</td>\n",
       "      <td>-0.685455</td>\n",
       "      <td>0.443639</td>\n",
       "      <td>1.110279</td>\n",
       "      <td>-0.337508</td>\n",
       "      <td>-0.905385</td>\n",
       "      <td>-0.589339</td>\n",
       "      <td>-0.615289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD8A</th>\n",
       "      <td>0.515832</td>\n",
       "      <td>3.633196</td>\n",
       "      <td>0.818810</td>\n",
       "      <td>-0.176498</td>\n",
       "      <td>-0.451516</td>\n",
       "      <td>-0.522069</td>\n",
       "      <td>-0.002288</td>\n",
       "      <td>-0.460104</td>\n",
       "      <td>-0.521519</td>\n",
       "      <td>-0.512798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046678</td>\n",
       "      <td>-0.519461</td>\n",
       "      <td>-0.397443</td>\n",
       "      <td>-0.433215</td>\n",
       "      <td>0.279004</td>\n",
       "      <td>-0.296561</td>\n",
       "      <td>-0.347329</td>\n",
       "      <td>-0.241276</td>\n",
       "      <td>3.818453</td>\n",
       "      <td>-0.162707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD8B</th>\n",
       "      <td>0.220158</td>\n",
       "      <td>4.561195</td>\n",
       "      <td>0.921434</td>\n",
       "      <td>-0.227858</td>\n",
       "      <td>-0.429290</td>\n",
       "      <td>-0.511012</td>\n",
       "      <td>0.500421</td>\n",
       "      <td>-0.449870</td>\n",
       "      <td>-0.518489</td>\n",
       "      <td>-0.520821</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162957</td>\n",
       "      <td>-0.511192</td>\n",
       "      <td>-0.261121</td>\n",
       "      <td>-0.453047</td>\n",
       "      <td>0.275589</td>\n",
       "      <td>-0.277537</td>\n",
       "      <td>-0.359942</td>\n",
       "      <td>-0.266876</td>\n",
       "      <td>3.902101</td>\n",
       "      <td>-0.084617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GZMA</th>\n",
       "      <td>0.169125</td>\n",
       "      <td>2.111791</td>\n",
       "      <td>0.711730</td>\n",
       "      <td>-0.140605</td>\n",
       "      <td>-0.362708</td>\n",
       "      <td>-0.531611</td>\n",
       "      <td>0.283079</td>\n",
       "      <td>-0.527910</td>\n",
       "      <td>-0.555377</td>\n",
       "      <td>-0.519452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024211</td>\n",
       "      <td>-0.552516</td>\n",
       "      <td>-0.447693</td>\n",
       "      <td>-0.433737</td>\n",
       "      <td>0.714233</td>\n",
       "      <td>-0.083080</td>\n",
       "      <td>-0.385502</td>\n",
       "      <td>-0.305114</td>\n",
       "      <td>2.291183</td>\n",
       "      <td>0.019123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GZMB</th>\n",
       "      <td>-0.051636</td>\n",
       "      <td>6.575586</td>\n",
       "      <td>0.515839</td>\n",
       "      <td>-0.018477</td>\n",
       "      <td>-0.315049</td>\n",
       "      <td>-0.489974</td>\n",
       "      <td>1.127235</td>\n",
       "      <td>-0.431023</td>\n",
       "      <td>-0.492219</td>\n",
       "      <td>-0.396725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613315</td>\n",
       "      <td>-0.480637</td>\n",
       "      <td>-0.442818</td>\n",
       "      <td>-0.336062</td>\n",
       "      <td>0.464937</td>\n",
       "      <td>-0.249683</td>\n",
       "      <td>-0.396567</td>\n",
       "      <td>-0.351070</td>\n",
       "      <td>0.291201</td>\n",
       "      <td>0.297645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRF1</th>\n",
       "      <td>0.279281</td>\n",
       "      <td>6.064225</td>\n",
       "      <td>0.572005</td>\n",
       "      <td>-0.206566</td>\n",
       "      <td>-0.372088</td>\n",
       "      <td>-0.483672</td>\n",
       "      <td>2.832222</td>\n",
       "      <td>-0.344526</td>\n",
       "      <td>-0.486797</td>\n",
       "      <td>-0.477997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125416</td>\n",
       "      <td>-0.472934</td>\n",
       "      <td>-0.361238</td>\n",
       "      <td>-0.377179</td>\n",
       "      <td>0.674092</td>\n",
       "      <td>-0.235528</td>\n",
       "      <td>-0.291784</td>\n",
       "      <td>-0.297436</td>\n",
       "      <td>2.324674</td>\n",
       "      <td>0.076410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1386 rows × 314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TCGA-D3-A3CE  TCGA-D9-A6E9  TCGA-FR-A729  TCGA-D3-A3CF  TCGA-WE-AA9Y  \\\n",
       "CSMD2       -0.054080     -0.229752     -0.195151     -0.127083      0.416151   \n",
       "ZC3H12D     -0.062392      0.787136      1.198162      0.525882     -0.155966   \n",
       "KLF15       -0.285557     -0.925922     -0.094339     -0.945225      2.075588   \n",
       "MRPL30      -1.103459      0.292058      1.357681      1.485900      0.622276   \n",
       "UCK1        -0.566261      0.194461     -0.750406      0.675687      0.012524   \n",
       "...               ...           ...           ...           ...           ...   \n",
       "CD8A         0.515832      3.633196      0.818810     -0.176498     -0.451516   \n",
       "CD8B         0.220158      4.561195      0.921434     -0.227858     -0.429290   \n",
       "GZMA         0.169125      2.111791      0.711730     -0.140605     -0.362708   \n",
       "GZMB        -0.051636      6.575586      0.515839     -0.018477     -0.315049   \n",
       "PRF1         0.279281      6.064225      0.572005     -0.206566     -0.372088   \n",
       "\n",
       "         TCGA-D3-A3CC  TCGA-Z2-AA3V  TCGA-GN-A8LL  TCGA-GN-A8LK  TCGA-FS-A1ZS  \\\n",
       "CSMD2       -0.156377     -0.246390     -0.297175     -0.224577     14.230808   \n",
       "ZC3H12D     -0.346858      0.678543     -0.486661     -0.475804     -0.440953   \n",
       "KLF15        0.052303      0.846139      1.212722     -0.419437     -1.190301   \n",
       "MRPL30      -0.069789     -1.869262     -0.388936     -0.312104     -0.999960   \n",
       "UCK1        -0.675303      4.375373      1.203905      2.453245     -1.252481   \n",
       "...               ...           ...           ...           ...           ...   \n",
       "CD8A        -0.522069     -0.002288     -0.460104     -0.521519     -0.512798   \n",
       "CD8B        -0.511012      0.500421     -0.449870     -0.518489     -0.520821   \n",
       "GZMA        -0.531611      0.283079     -0.527910     -0.555377     -0.519452   \n",
       "GZMB        -0.489974      1.127235     -0.431023     -0.492219     -0.396725   \n",
       "PRF1        -0.483672      2.832222     -0.344526     -0.486797     -0.477997   \n",
       "\n",
       "         ...  TCGA-EE-A2M5  TCGA-D3-A5GL  TCGA-EE-A2M7  TCGA-EE-A2M6  \\\n",
       "CSMD2    ...      7.849712     -0.155544     -0.246903     -0.283339   \n",
       "ZC3H12D  ...     -0.401698     -0.484379      0.023117     -0.290790   \n",
       "KLF15    ...     -1.198349     -0.739588      0.785233     -0.075452   \n",
       "MRPL30   ...     -0.062576      0.304411     -0.620333      2.073774   \n",
       "UCK1     ...     -0.632063     -0.559619     -0.579764     -0.685455   \n",
       "...      ...           ...           ...           ...           ...   \n",
       "CD8A     ...     -0.046678     -0.519461     -0.397443     -0.433215   \n",
       "CD8B     ...     -0.162957     -0.511192     -0.261121     -0.453047   \n",
       "GZMA     ...      0.024211     -0.552516     -0.447693     -0.433737   \n",
       "GZMB     ...      0.613315     -0.480637     -0.442818     -0.336062   \n",
       "PRF1     ...      0.125416     -0.472934     -0.361238     -0.377179   \n",
       "\n",
       "         TCGA-D9-A3Z1  TCGA-D9-A3Z3  TCGA-EE-A3J7  TCGA-EE-A3AF  TCGA-EE-A2M8  \\\n",
       "CSMD2       -0.104239     -0.173656     -0.162199     -0.148308     -0.045141   \n",
       "ZC3H12D      0.175650      0.678512     -0.407778     -0.289600      1.769030   \n",
       "KLF15       -0.838268     -0.032067      3.523628      0.981693     -0.790780   \n",
       "MRPL30       0.047338     -1.527091     -0.306298     -1.364359     -0.513214   \n",
       "UCK1         0.443639      1.110279     -0.337508     -0.905385     -0.589339   \n",
       "...               ...           ...           ...           ...           ...   \n",
       "CD8A         0.279004     -0.296561     -0.347329     -0.241276      3.818453   \n",
       "CD8B         0.275589     -0.277537     -0.359942     -0.266876      3.902101   \n",
       "GZMA         0.714233     -0.083080     -0.385502     -0.305114      2.291183   \n",
       "GZMB         0.464937     -0.249683     -0.396567     -0.351070      0.291201   \n",
       "PRF1         0.674092     -0.235528     -0.291784     -0.297436      2.324674   \n",
       "\n",
       "         TCGA-GF-A6C9  \n",
       "CSMD2        0.433603  \n",
       "ZC3H12D      1.608189  \n",
       "KLF15       -0.560695  \n",
       "MRPL30      -0.786474  \n",
       "UCK1        -0.615289  \n",
       "...               ...  \n",
       "CD8A        -0.162707  \n",
       "CD8B        -0.084617  \n",
       "GZMA         0.019123  \n",
       "GZMB         0.297645  \n",
       "PRF1         0.076410  \n",
       "\n",
       "[1386 rows x 314 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test correlation network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1386,)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CSMD2', 'ZC3H12D', 'KLF15', 'MRPL30', 'UCK1', 'AMPD3', 'LRP10',\n",
       "       'CDYL2', 'NLGN1', 'TSEN2',\n",
       "       ...\n",
       "       'COL6A2', 'COL6A3', 'COL6A1', 'COL8A2', 'C11orf88', 'CD8A', 'CD8B',\n",
       "       'GZMA', 'GZMB', 'PRF1'],\n",
       "      dtype='object', length=1386)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_selected = im.index[gene_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ACY1', 'WIPF1', 'HGF', 'ADGRA1', 'PLCL2', 'COL10A1', 'HIST1H2AM',\n",
       "       'RFX8', 'HTR5A', 'CXCL6', 'CDK2', 'PMEL', 'OR2M4', 'SPRED3', 'HLA-DOA',\n",
       "       'NTM', 'NANOG', 'POM121L4P', 'PLXDC2', 'GPR82', 'PPP1R14C', 'ALPL',\n",
       "       'ANKRD30A', 'FAM69B', 'PSD', 'TBC1D16', 'EDARADD', 'WNT9A', 'STK36',\n",
       "       'CYBB', 'CALHM3', 'ZNF542P', 'TNNI2', 'NLRP6', 'AIRE', 'CXorf21',\n",
       "       'TEX35', 'PIK3R2', 'TLR4', 'SCARNA11', 'CCR1', 'NLRC4', 'SLC5A5',\n",
       "       'MPPED1', 'HLA-B', 'TBXAS1', 'GPR141', 'HLA-DRA', 'CES1P1', 'PCNAP1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_indexes = pd.read_csv('./data/immune/raw/Tcell.CSN.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene1</th>\n",
       "      <th>gene2</th>\n",
       "      <th>sampleID</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GGTA1P</td>\n",
       "      <td>BLNK</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>6.459650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GGTA1P</td>\n",
       "      <td>FERMT3</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>2.815943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GGTA1P</td>\n",
       "      <td>LAX1</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>4.768403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GGTA1P</td>\n",
       "      <td>STON2</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>4.030512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GGTA1P</td>\n",
       "      <td>DGKZ</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>3.423227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7760782</th>\n",
       "      <td>COL8A2</td>\n",
       "      <td>C11orf88</td>\n",
       "      <td>TCGA-GF-A6C9</td>\n",
       "      <td>2.709702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7760783</th>\n",
       "      <td>C11orf88</td>\n",
       "      <td>GZMB</td>\n",
       "      <td>TCGA-GF-A6C9</td>\n",
       "      <td>2.615589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7760784</th>\n",
       "      <td>GZMA</td>\n",
       "      <td>GZMB</td>\n",
       "      <td>TCGA-GF-A6C9</td>\n",
       "      <td>3.536582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7760785</th>\n",
       "      <td>GZMA</td>\n",
       "      <td>PRF1</td>\n",
       "      <td>TCGA-GF-A6C9</td>\n",
       "      <td>4.895382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7760786</th>\n",
       "      <td>GZMB</td>\n",
       "      <td>PRF1</td>\n",
       "      <td>TCGA-GF-A6C9</td>\n",
       "      <td>5.852365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7760787 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gene1     gene2      sampleID     value\n",
       "0          GGTA1P      BLNK  TCGA-D3-A3CE  6.459650\n",
       "1          GGTA1P    FERMT3  TCGA-D3-A3CE  2.815943\n",
       "2          GGTA1P      LAX1  TCGA-D3-A3CE  4.768403\n",
       "3          GGTA1P     STON2  TCGA-D3-A3CE  4.030512\n",
       "4          GGTA1P      DGKZ  TCGA-D3-A3CE  3.423227\n",
       "...           ...       ...           ...       ...\n",
       "7760782    COL8A2  C11orf88  TCGA-GF-A6C9  2.709702\n",
       "7760783  C11orf88      GZMB  TCGA-GF-A6C9  2.615589\n",
       "7760784      GZMA      GZMB  TCGA-GF-A6C9  3.536582\n",
       "7760785      GZMA      PRF1  TCGA-GF-A6C9  4.895382\n",
       "7760786      GZMB      PRF1  TCGA-GF-A6C9  5.852365\n",
       "\n",
       "[7760787 rows x 4 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_indexes_selected_by_sample = edge_indexes[edge_indexes['sampleID'].isin(im.columns[mask])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene1</th>\n",
       "      <th>gene2</th>\n",
       "      <th>sampleID</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GGTA1P</td>\n",
       "      <td>BLNK</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>6.459650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GGTA1P</td>\n",
       "      <td>FERMT3</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>2.815943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GGTA1P</td>\n",
       "      <td>LAX1</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>4.768403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GGTA1P</td>\n",
       "      <td>STON2</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>4.030512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GGTA1P</td>\n",
       "      <td>DGKZ</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>3.423227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7660304</th>\n",
       "      <td>CD8A</td>\n",
       "      <td>GZMA</td>\n",
       "      <td>TCGA-EE-A2M8</td>\n",
       "      <td>14.199730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7660305</th>\n",
       "      <td>CD8A</td>\n",
       "      <td>PRF1</td>\n",
       "      <td>TCGA-EE-A2M8</td>\n",
       "      <td>13.808805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7660306</th>\n",
       "      <td>CD8B</td>\n",
       "      <td>GZMA</td>\n",
       "      <td>TCGA-EE-A2M8</td>\n",
       "      <td>13.415021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7660307</th>\n",
       "      <td>CD8B</td>\n",
       "      <td>PRF1</td>\n",
       "      <td>TCGA-EE-A2M8</td>\n",
       "      <td>13.103656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7660308</th>\n",
       "      <td>GZMA</td>\n",
       "      <td>PRF1</td>\n",
       "      <td>TCGA-EE-A2M8</td>\n",
       "      <td>12.178345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5052348 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          gene1   gene2      sampleID      value\n",
       "0        GGTA1P    BLNK  TCGA-D3-A3CE   6.459650\n",
       "1        GGTA1P  FERMT3  TCGA-D3-A3CE   2.815943\n",
       "2        GGTA1P    LAX1  TCGA-D3-A3CE   4.768403\n",
       "3        GGTA1P   STON2  TCGA-D3-A3CE   4.030512\n",
       "4        GGTA1P    DGKZ  TCGA-D3-A3CE   3.423227\n",
       "...         ...     ...           ...        ...\n",
       "7660304    CD8A    GZMA  TCGA-EE-A2M8  14.199730\n",
       "7660305    CD8A    PRF1  TCGA-EE-A2M8  13.808805\n",
       "7660306    CD8B    GZMA  TCGA-EE-A2M8  13.415021\n",
       "7660307    CD8B    PRF1  TCGA-EE-A2M8  13.103656\n",
       "7660308    GZMA    PRF1  TCGA-EE-A2M8  12.178345\n",
       "\n",
       "[5052348 rows x 4 columns]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_indexes_selected_by_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_indexes_selected_by_sample_and_gene1 = edge_indexes_selected_by_sample[edge_indexes_selected_by_sample['gene1'].isin(gene_selected)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene1</th>\n",
       "      <th>gene2</th>\n",
       "      <th>sampleID</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4209</th>\n",
       "      <td>PLCL2</td>\n",
       "      <td>CD1B</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>2.397982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4210</th>\n",
       "      <td>PLCL2</td>\n",
       "      <td>LCP1</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>2.397982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4211</th>\n",
       "      <td>PLCL2</td>\n",
       "      <td>VCAN</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>2.917266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4212</th>\n",
       "      <td>PLCL2</td>\n",
       "      <td>PRDM1</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>2.917266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4213</th>\n",
       "      <td>PLCL2</td>\n",
       "      <td>CD180</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>2.397982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7658800</th>\n",
       "      <td>HLA-DRA</td>\n",
       "      <td>C11orf88</td>\n",
       "      <td>TCGA-EE-A2M8</td>\n",
       "      <td>4.439210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7658801</th>\n",
       "      <td>HLA-DRA</td>\n",
       "      <td>CD8A</td>\n",
       "      <td>TCGA-EE-A2M8</td>\n",
       "      <td>9.056360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7658802</th>\n",
       "      <td>HLA-DRA</td>\n",
       "      <td>CD8B</td>\n",
       "      <td>TCGA-EE-A2M8</td>\n",
       "      <td>8.190699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7658803</th>\n",
       "      <td>HLA-DRA</td>\n",
       "      <td>GZMA</td>\n",
       "      <td>TCGA-EE-A2M8</td>\n",
       "      <td>8.397912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7658804</th>\n",
       "      <td>HLA-DRA</td>\n",
       "      <td>PRF1</td>\n",
       "      <td>TCGA-EE-A2M8</td>\n",
       "      <td>7.202176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111337 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           gene1     gene2      sampleID     value\n",
       "4209       PLCL2      CD1B  TCGA-D3-A3CE  2.397982\n",
       "4210       PLCL2      LCP1  TCGA-D3-A3CE  2.397982\n",
       "4211       PLCL2      VCAN  TCGA-D3-A3CE  2.917266\n",
       "4212       PLCL2     PRDM1  TCGA-D3-A3CE  2.917266\n",
       "4213       PLCL2     CD180  TCGA-D3-A3CE  2.397982\n",
       "...          ...       ...           ...       ...\n",
       "7658800  HLA-DRA  C11orf88  TCGA-EE-A2M8  4.439210\n",
       "7658801  HLA-DRA      CD8A  TCGA-EE-A2M8  9.056360\n",
       "7658802  HLA-DRA      CD8B  TCGA-EE-A2M8  8.190699\n",
       "7658803  HLA-DRA      GZMA  TCGA-EE-A2M8  8.397912\n",
       "7658804  HLA-DRA      PRF1  TCGA-EE-A2M8  7.202176\n",
       "\n",
       "[111337 rows x 4 columns]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_indexes_selected_by_sample_and_gene1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_indexes_selected_by_sample_and_gene1_and_gene2 = edge_indexes_selected_by_sample_and_gene1[edge_indexes_selected_by_sample_and_gene1['gene2'].isin(gene_selected)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene1</th>\n",
       "      <th>gene2</th>\n",
       "      <th>sampleID</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22361</th>\n",
       "      <td>CYBB</td>\n",
       "      <td>CXorf21</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>6.459650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22376</th>\n",
       "      <td>CYBB</td>\n",
       "      <td>TLR4</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>5.111221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22379</th>\n",
       "      <td>CYBB</td>\n",
       "      <td>CCR1</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>4.030512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22385</th>\n",
       "      <td>CYBB</td>\n",
       "      <td>NLRC4</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>5.245081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24142</th>\n",
       "      <td>CXorf21</td>\n",
       "      <td>TLR4</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>4.030512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7656472</th>\n",
       "      <td>NLRC4</td>\n",
       "      <td>HLA-DRA</td>\n",
       "      <td>TCGA-EE-A2M8</td>\n",
       "      <td>8.000349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7657484</th>\n",
       "      <td>HLA-B</td>\n",
       "      <td>TBXAS1</td>\n",
       "      <td>TCGA-EE-A2M8</td>\n",
       "      <td>2.353183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7657487</th>\n",
       "      <td>HLA-B</td>\n",
       "      <td>GPR141</td>\n",
       "      <td>TCGA-EE-A2M8</td>\n",
       "      <td>5.451294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7657497</th>\n",
       "      <td>HLA-B</td>\n",
       "      <td>HLA-DRA</td>\n",
       "      <td>TCGA-EE-A2M8</td>\n",
       "      <td>9.597622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7658013</th>\n",
       "      <td>GPR141</td>\n",
       "      <td>HLA-DRA</td>\n",
       "      <td>TCGA-EE-A2M8</td>\n",
       "      <td>6.652325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4431 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           gene1    gene2      sampleID     value\n",
       "22361       CYBB  CXorf21  TCGA-D3-A3CE  6.459650\n",
       "22376       CYBB     TLR4  TCGA-D3-A3CE  5.111221\n",
       "22379       CYBB     CCR1  TCGA-D3-A3CE  4.030512\n",
       "22385       CYBB    NLRC4  TCGA-D3-A3CE  5.245081\n",
       "24142    CXorf21     TLR4  TCGA-D3-A3CE  4.030512\n",
       "...          ...      ...           ...       ...\n",
       "7656472    NLRC4  HLA-DRA  TCGA-EE-A2M8  8.000349\n",
       "7657484    HLA-B   TBXAS1  TCGA-EE-A2M8  2.353183\n",
       "7657487    HLA-B   GPR141  TCGA-EE-A2M8  5.451294\n",
       "7657497    HLA-B  HLA-DRA  TCGA-EE-A2M8  9.597622\n",
       "7658013   GPR141  HLA-DRA  TCGA-EE-A2M8  6.652325\n",
       "\n",
       "[4431 rows x 4 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_indexes_selected_by_sample_and_gene1_and_gene2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = [[], []]\n",
    "edge_index[0] = edge_indexes_selected_by_sample_and_gene1_and_gene2['gene1'].map(lambda x: gene_selected.get_loc(x)).values\n",
    "edge_index[1] = edge_indexes_selected_by_sample_and_gene1_and_gene2['gene2'].map(lambda x: gene_selected.get_loc(x)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im[im.columns[mask]][gene_mask].T.corr().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_corr = im[im.columns[mask]][gene_mask].T.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACY1</th>\n",
       "      <th>WIPF1</th>\n",
       "      <th>HGF</th>\n",
       "      <th>ADGRA1</th>\n",
       "      <th>PLCL2</th>\n",
       "      <th>COL10A1</th>\n",
       "      <th>HIST1H2AM</th>\n",
       "      <th>RFX8</th>\n",
       "      <th>HTR5A</th>\n",
       "      <th>CXCL6</th>\n",
       "      <th>...</th>\n",
       "      <th>CCR1</th>\n",
       "      <th>NLRC4</th>\n",
       "      <th>SLC5A5</th>\n",
       "      <th>MPPED1</th>\n",
       "      <th>HLA-B</th>\n",
       "      <th>TBXAS1</th>\n",
       "      <th>GPR141</th>\n",
       "      <th>HLA-DRA</th>\n",
       "      <th>CES1P1</th>\n",
       "      <th>PCNAP1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACY1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.204649</td>\n",
       "      <td>-0.022824</td>\n",
       "      <td>-0.020961</td>\n",
       "      <td>-0.349030</td>\n",
       "      <td>-0.134046</td>\n",
       "      <td>0.287491</td>\n",
       "      <td>-0.139039</td>\n",
       "      <td>-0.054540</td>\n",
       "      <td>-0.056513</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.284266</td>\n",
       "      <td>-0.334402</td>\n",
       "      <td>-0.048202</td>\n",
       "      <td>0.019921</td>\n",
       "      <td>-0.165554</td>\n",
       "      <td>-0.103870</td>\n",
       "      <td>-0.292375</td>\n",
       "      <td>-0.257832</td>\n",
       "      <td>-0.037957</td>\n",
       "      <td>-0.046990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WIPF1</th>\n",
       "      <td>-0.204649</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.234293</td>\n",
       "      <td>-0.034678</td>\n",
       "      <td>0.296577</td>\n",
       "      <td>0.056953</td>\n",
       "      <td>-0.167969</td>\n",
       "      <td>0.184788</td>\n",
       "      <td>-0.025678</td>\n",
       "      <td>0.085137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463699</td>\n",
       "      <td>0.414166</td>\n",
       "      <td>-0.028920</td>\n",
       "      <td>-0.069754</td>\n",
       "      <td>0.227420</td>\n",
       "      <td>0.296426</td>\n",
       "      <td>0.400492</td>\n",
       "      <td>0.313661</td>\n",
       "      <td>-0.025722</td>\n",
       "      <td>0.060322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGF</th>\n",
       "      <td>-0.022824</td>\n",
       "      <td>0.234293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014601</td>\n",
       "      <td>-0.055203</td>\n",
       "      <td>0.045808</td>\n",
       "      <td>-0.006186</td>\n",
       "      <td>0.299265</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.092573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093686</td>\n",
       "      <td>0.102220</td>\n",
       "      <td>-0.011633</td>\n",
       "      <td>-0.010444</td>\n",
       "      <td>-0.001873</td>\n",
       "      <td>0.116505</td>\n",
       "      <td>0.027690</td>\n",
       "      <td>-0.039828</td>\n",
       "      <td>-0.018013</td>\n",
       "      <td>-0.009153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADGRA1</th>\n",
       "      <td>-0.020961</td>\n",
       "      <td>-0.034678</td>\n",
       "      <td>-0.014601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.098894</td>\n",
       "      <td>0.012882</td>\n",
       "      <td>0.046039</td>\n",
       "      <td>-0.018780</td>\n",
       "      <td>0.051725</td>\n",
       "      <td>-0.019164</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009401</td>\n",
       "      <td>0.049155</td>\n",
       "      <td>0.366437</td>\n",
       "      <td>-0.009141</td>\n",
       "      <td>-0.040732</td>\n",
       "      <td>-0.020897</td>\n",
       "      <td>0.046167</td>\n",
       "      <td>-0.004245</td>\n",
       "      <td>0.009113</td>\n",
       "      <td>-0.004106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLCL2</th>\n",
       "      <td>-0.349030</td>\n",
       "      <td>0.296577</td>\n",
       "      <td>-0.055203</td>\n",
       "      <td>0.098894</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.081274</td>\n",
       "      <td>-0.163540</td>\n",
       "      <td>0.083205</td>\n",
       "      <td>-0.064729</td>\n",
       "      <td>-0.023362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344361</td>\n",
       "      <td>0.531824</td>\n",
       "      <td>-0.019463</td>\n",
       "      <td>-0.071125</td>\n",
       "      <td>0.355716</td>\n",
       "      <td>0.121938</td>\n",
       "      <td>0.509011</td>\n",
       "      <td>0.512637</td>\n",
       "      <td>0.070306</td>\n",
       "      <td>-0.048723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COL10A1</th>\n",
       "      <td>-0.134046</td>\n",
       "      <td>0.056953</td>\n",
       "      <td>0.045808</td>\n",
       "      <td>0.012882</td>\n",
       "      <td>0.081274</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.156296</td>\n",
       "      <td>0.274167</td>\n",
       "      <td>-0.029997</td>\n",
       "      <td>0.160042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.194335</td>\n",
       "      <td>-0.013907</td>\n",
       "      <td>-0.025520</td>\n",
       "      <td>0.071370</td>\n",
       "      <td>0.154639</td>\n",
       "      <td>0.145470</td>\n",
       "      <td>0.117725</td>\n",
       "      <td>0.053181</td>\n",
       "      <td>-0.015888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HIST1H2AM</th>\n",
       "      <td>0.287491</td>\n",
       "      <td>-0.167969</td>\n",
       "      <td>-0.006186</td>\n",
       "      <td>0.046039</td>\n",
       "      <td>-0.163540</td>\n",
       "      <td>-0.156296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.129061</td>\n",
       "      <td>0.059908</td>\n",
       "      <td>0.020767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178363</td>\n",
       "      <td>-0.162994</td>\n",
       "      <td>-0.045696</td>\n",
       "      <td>0.045716</td>\n",
       "      <td>-0.010572</td>\n",
       "      <td>-0.164143</td>\n",
       "      <td>-0.123003</td>\n",
       "      <td>-0.113595</td>\n",
       "      <td>-0.030331</td>\n",
       "      <td>0.130307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFX8</th>\n",
       "      <td>-0.139039</td>\n",
       "      <td>0.184788</td>\n",
       "      <td>0.299265</td>\n",
       "      <td>-0.018780</td>\n",
       "      <td>0.083205</td>\n",
       "      <td>0.274167</td>\n",
       "      <td>-0.129061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.036186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139425</td>\n",
       "      <td>0.101822</td>\n",
       "      <td>-0.007522</td>\n",
       "      <td>-0.020715</td>\n",
       "      <td>-0.010833</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.034162</td>\n",
       "      <td>-0.047295</td>\n",
       "      <td>0.140210</td>\n",
       "      <td>-0.015806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HTR5A</th>\n",
       "      <td>-0.054540</td>\n",
       "      <td>-0.025678</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.051725</td>\n",
       "      <td>-0.064729</td>\n",
       "      <td>-0.029997</td>\n",
       "      <td>0.059908</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015236</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023807</td>\n",
       "      <td>-0.028586</td>\n",
       "      <td>-0.011586</td>\n",
       "      <td>-0.011767</td>\n",
       "      <td>-0.070753</td>\n",
       "      <td>0.094177</td>\n",
       "      <td>-0.066088</td>\n",
       "      <td>-0.047351</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>-0.011676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CXCL6</th>\n",
       "      <td>-0.056513</td>\n",
       "      <td>0.085137</td>\n",
       "      <td>0.092573</td>\n",
       "      <td>-0.019164</td>\n",
       "      <td>-0.023362</td>\n",
       "      <td>0.160042</td>\n",
       "      <td>0.020767</td>\n",
       "      <td>0.036186</td>\n",
       "      <td>0.015236</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159305</td>\n",
       "      <td>0.145501</td>\n",
       "      <td>-0.002946</td>\n",
       "      <td>-0.014481</td>\n",
       "      <td>0.066510</td>\n",
       "      <td>0.032749</td>\n",
       "      <td>0.116464</td>\n",
       "      <td>0.067687</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>-0.013585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDK2</th>\n",
       "      <td>0.317515</td>\n",
       "      <td>-0.306191</td>\n",
       "      <td>-0.111271</td>\n",
       "      <td>-0.070078</td>\n",
       "      <td>-0.215249</td>\n",
       "      <td>-0.149692</td>\n",
       "      <td>0.142863</td>\n",
       "      <td>-0.229001</td>\n",
       "      <td>-0.058021</td>\n",
       "      <td>-0.090999</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.302146</td>\n",
       "      <td>-0.348398</td>\n",
       "      <td>-0.067768</td>\n",
       "      <td>-0.010944</td>\n",
       "      <td>-0.159081</td>\n",
       "      <td>-0.281088</td>\n",
       "      <td>-0.198010</td>\n",
       "      <td>-0.161399</td>\n",
       "      <td>-0.077708</td>\n",
       "      <td>-0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PMEL</th>\n",
       "      <td>0.452402</td>\n",
       "      <td>-0.285077</td>\n",
       "      <td>-0.104135</td>\n",
       "      <td>-0.043964</td>\n",
       "      <td>-0.271479</td>\n",
       "      <td>-0.127885</td>\n",
       "      <td>0.170178</td>\n",
       "      <td>-0.195535</td>\n",
       "      <td>-0.058973</td>\n",
       "      <td>-0.100009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268332</td>\n",
       "      <td>-0.355681</td>\n",
       "      <td>-0.041892</td>\n",
       "      <td>0.011129</td>\n",
       "      <td>-0.165733</td>\n",
       "      <td>-0.229864</td>\n",
       "      <td>-0.224307</td>\n",
       "      <td>-0.189147</td>\n",
       "      <td>-0.050997</td>\n",
       "      <td>-0.005889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR2M4</th>\n",
       "      <td>-0.115802</td>\n",
       "      <td>0.263896</td>\n",
       "      <td>0.394022</td>\n",
       "      <td>-0.023728</td>\n",
       "      <td>0.123088</td>\n",
       "      <td>0.025771</td>\n",
       "      <td>-0.090239</td>\n",
       "      <td>0.380518</td>\n",
       "      <td>-0.034260</td>\n",
       "      <td>0.029189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126688</td>\n",
       "      <td>0.167923</td>\n",
       "      <td>-0.013204</td>\n",
       "      <td>-0.014948</td>\n",
       "      <td>0.014752</td>\n",
       "      <td>0.073770</td>\n",
       "      <td>0.096073</td>\n",
       "      <td>0.129354</td>\n",
       "      <td>-0.023650</td>\n",
       "      <td>-0.013769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPRED3</th>\n",
       "      <td>-0.137780</td>\n",
       "      <td>0.346872</td>\n",
       "      <td>0.539141</td>\n",
       "      <td>-0.037198</td>\n",
       "      <td>-0.039463</td>\n",
       "      <td>0.134718</td>\n",
       "      <td>-0.107959</td>\n",
       "      <td>0.535268</td>\n",
       "      <td>0.042052</td>\n",
       "      <td>0.174183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110237</td>\n",
       "      <td>0.067319</td>\n",
       "      <td>-0.020554</td>\n",
       "      <td>-0.028614</td>\n",
       "      <td>-0.016770</td>\n",
       "      <td>0.216678</td>\n",
       "      <td>0.029301</td>\n",
       "      <td>-0.078761</td>\n",
       "      <td>0.015697</td>\n",
       "      <td>-0.023327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HLA-DOA</th>\n",
       "      <td>-0.223811</td>\n",
       "      <td>0.259146</td>\n",
       "      <td>-0.034771</td>\n",
       "      <td>-0.001138</td>\n",
       "      <td>0.448426</td>\n",
       "      <td>0.044411</td>\n",
       "      <td>-0.087345</td>\n",
       "      <td>-0.041454</td>\n",
       "      <td>-0.040207</td>\n",
       "      <td>0.015432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407114</td>\n",
       "      <td>0.492460</td>\n",
       "      <td>-0.013044</td>\n",
       "      <td>-0.035128</td>\n",
       "      <td>0.668090</td>\n",
       "      <td>0.249526</td>\n",
       "      <td>0.546210</td>\n",
       "      <td>0.834231</td>\n",
       "      <td>-0.001139</td>\n",
       "      <td>-0.031600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NTM</th>\n",
       "      <td>-0.192422</td>\n",
       "      <td>0.284010</td>\n",
       "      <td>0.131434</td>\n",
       "      <td>-0.022980</td>\n",
       "      <td>0.035313</td>\n",
       "      <td>0.114953</td>\n",
       "      <td>-0.150809</td>\n",
       "      <td>0.311891</td>\n",
       "      <td>-0.026912</td>\n",
       "      <td>0.052455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146216</td>\n",
       "      <td>0.138594</td>\n",
       "      <td>-0.020476</td>\n",
       "      <td>-0.016045</td>\n",
       "      <td>-0.023799</td>\n",
       "      <td>0.120416</td>\n",
       "      <td>0.104975</td>\n",
       "      <td>0.039516</td>\n",
       "      <td>0.067430</td>\n",
       "      <td>-0.021332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NANOG</th>\n",
       "      <td>-0.086761</td>\n",
       "      <td>-0.046270</td>\n",
       "      <td>0.016595</td>\n",
       "      <td>0.012342</td>\n",
       "      <td>-0.017363</td>\n",
       "      <td>-0.024822</td>\n",
       "      <td>0.009193</td>\n",
       "      <td>-0.016863</td>\n",
       "      <td>0.307958</td>\n",
       "      <td>-0.011745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046468</td>\n",
       "      <td>0.026469</td>\n",
       "      <td>-0.009892</td>\n",
       "      <td>-0.007865</td>\n",
       "      <td>-0.073193</td>\n",
       "      <td>-0.005478</td>\n",
       "      <td>-0.044624</td>\n",
       "      <td>-0.044738</td>\n",
       "      <td>-0.008928</td>\n",
       "      <td>-0.007990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POM121L4P</th>\n",
       "      <td>0.006662</td>\n",
       "      <td>0.111346</td>\n",
       "      <td>0.027602</td>\n",
       "      <td>-0.008127</td>\n",
       "      <td>0.140562</td>\n",
       "      <td>0.133349</td>\n",
       "      <td>-0.030035</td>\n",
       "      <td>0.037658</td>\n",
       "      <td>0.053486</td>\n",
       "      <td>-0.039957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019603</td>\n",
       "      <td>0.126414</td>\n",
       "      <td>-0.013826</td>\n",
       "      <td>-0.029827</td>\n",
       "      <td>0.094886</td>\n",
       "      <td>0.055685</td>\n",
       "      <td>0.115600</td>\n",
       "      <td>0.130344</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>-0.028463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLXDC2</th>\n",
       "      <td>-0.309935</td>\n",
       "      <td>0.326517</td>\n",
       "      <td>0.127333</td>\n",
       "      <td>0.188833</td>\n",
       "      <td>0.334190</td>\n",
       "      <td>0.473467</td>\n",
       "      <td>-0.216400</td>\n",
       "      <td>0.145244</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.066001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574861</td>\n",
       "      <td>0.610265</td>\n",
       "      <td>-0.010848</td>\n",
       "      <td>-0.056813</td>\n",
       "      <td>0.226467</td>\n",
       "      <td>0.312605</td>\n",
       "      <td>0.565559</td>\n",
       "      <td>0.497645</td>\n",
       "      <td>0.103824</td>\n",
       "      <td>-0.034441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPR82</th>\n",
       "      <td>-0.254121</td>\n",
       "      <td>0.384940</td>\n",
       "      <td>0.110756</td>\n",
       "      <td>0.034297</td>\n",
       "      <td>0.482105</td>\n",
       "      <td>0.041146</td>\n",
       "      <td>-0.170199</td>\n",
       "      <td>0.045652</td>\n",
       "      <td>-0.055755</td>\n",
       "      <td>0.089757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445192</td>\n",
       "      <td>0.574343</td>\n",
       "      <td>-0.025831</td>\n",
       "      <td>-0.046739</td>\n",
       "      <td>0.224765</td>\n",
       "      <td>0.268023</td>\n",
       "      <td>0.542670</td>\n",
       "      <td>0.461570</td>\n",
       "      <td>-0.034771</td>\n",
       "      <td>-0.003683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPP1R14C</th>\n",
       "      <td>-0.095201</td>\n",
       "      <td>0.094191</td>\n",
       "      <td>-0.051668</td>\n",
       "      <td>-0.048721</td>\n",
       "      <td>-0.072819</td>\n",
       "      <td>-0.032061</td>\n",
       "      <td>-0.018855</td>\n",
       "      <td>-0.044516</td>\n",
       "      <td>-0.044988</td>\n",
       "      <td>-0.007662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091430</td>\n",
       "      <td>-0.016702</td>\n",
       "      <td>-0.032938</td>\n",
       "      <td>-0.029927</td>\n",
       "      <td>0.062120</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>-0.000628</td>\n",
       "      <td>0.032739</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>-0.027272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALPL</th>\n",
       "      <td>-0.002692</td>\n",
       "      <td>0.085826</td>\n",
       "      <td>-0.012189</td>\n",
       "      <td>-0.005562</td>\n",
       "      <td>0.145346</td>\n",
       "      <td>0.088378</td>\n",
       "      <td>-0.053117</td>\n",
       "      <td>0.216934</td>\n",
       "      <td>-0.033577</td>\n",
       "      <td>0.093984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196258</td>\n",
       "      <td>0.261393</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>-0.026415</td>\n",
       "      <td>0.129588</td>\n",
       "      <td>0.185408</td>\n",
       "      <td>0.150852</td>\n",
       "      <td>0.180628</td>\n",
       "      <td>0.130078</td>\n",
       "      <td>-0.020905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANKRD30A</th>\n",
       "      <td>-0.053467</td>\n",
       "      <td>-0.041122</td>\n",
       "      <td>-0.007231</td>\n",
       "      <td>-0.012530</td>\n",
       "      <td>-0.051412</td>\n",
       "      <td>-0.057609</td>\n",
       "      <td>0.047503</td>\n",
       "      <td>0.009607</td>\n",
       "      <td>0.678646</td>\n",
       "      <td>0.037062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089345</td>\n",
       "      <td>-0.063983</td>\n",
       "      <td>-0.012291</td>\n",
       "      <td>-0.004990</td>\n",
       "      <td>-0.069762</td>\n",
       "      <td>0.026521</td>\n",
       "      <td>-0.085791</td>\n",
       "      <td>-0.098970</td>\n",
       "      <td>0.122022</td>\n",
       "      <td>-0.010709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAM69B</th>\n",
       "      <td>0.468095</td>\n",
       "      <td>-0.403295</td>\n",
       "      <td>-0.133771</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>-0.297142</td>\n",
       "      <td>-0.173547</td>\n",
       "      <td>0.142798</td>\n",
       "      <td>-0.236524</td>\n",
       "      <td>-0.005700</td>\n",
       "      <td>-0.104368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.330471</td>\n",
       "      <td>-0.352998</td>\n",
       "      <td>-0.019102</td>\n",
       "      <td>0.075919</td>\n",
       "      <td>-0.187458</td>\n",
       "      <td>-0.202578</td>\n",
       "      <td>-0.285105</td>\n",
       "      <td>-0.227035</td>\n",
       "      <td>-0.087145</td>\n",
       "      <td>0.112603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSD</th>\n",
       "      <td>0.163318</td>\n",
       "      <td>0.021492</td>\n",
       "      <td>0.036035</td>\n",
       "      <td>0.076843</td>\n",
       "      <td>-0.100160</td>\n",
       "      <td>0.043219</td>\n",
       "      <td>0.025857</td>\n",
       "      <td>0.076217</td>\n",
       "      <td>0.092214</td>\n",
       "      <td>0.215177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012171</td>\n",
       "      <td>0.079027</td>\n",
       "      <td>-0.024800</td>\n",
       "      <td>-0.035374</td>\n",
       "      <td>-0.053335</td>\n",
       "      <td>0.106785</td>\n",
       "      <td>-0.068882</td>\n",
       "      <td>-0.026245</td>\n",
       "      <td>0.104854</td>\n",
       "      <td>-0.019590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TBC1D16</th>\n",
       "      <td>0.322266</td>\n",
       "      <td>-0.311996</td>\n",
       "      <td>-0.100576</td>\n",
       "      <td>-0.046676</td>\n",
       "      <td>-0.241435</td>\n",
       "      <td>-0.119672</td>\n",
       "      <td>0.308000</td>\n",
       "      <td>-0.189544</td>\n",
       "      <td>-0.044427</td>\n",
       "      <td>-0.106282</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.308345</td>\n",
       "      <td>-0.376941</td>\n",
       "      <td>-0.040195</td>\n",
       "      <td>0.104095</td>\n",
       "      <td>-0.178263</td>\n",
       "      <td>-0.223512</td>\n",
       "      <td>-0.261106</td>\n",
       "      <td>-0.221512</td>\n",
       "      <td>-0.064847</td>\n",
       "      <td>0.092782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDARADD</th>\n",
       "      <td>-0.112585</td>\n",
       "      <td>0.012914</td>\n",
       "      <td>-0.052071</td>\n",
       "      <td>0.006835</td>\n",
       "      <td>0.086595</td>\n",
       "      <td>0.036174</td>\n",
       "      <td>0.020692</td>\n",
       "      <td>0.006062</td>\n",
       "      <td>0.188596</td>\n",
       "      <td>-0.015316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081897</td>\n",
       "      <td>0.080870</td>\n",
       "      <td>-0.041182</td>\n",
       "      <td>-0.028766</td>\n",
       "      <td>0.176052</td>\n",
       "      <td>0.041992</td>\n",
       "      <td>0.129936</td>\n",
       "      <td>0.161213</td>\n",
       "      <td>0.023419</td>\n",
       "      <td>0.024078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WNT9A</th>\n",
       "      <td>-0.110394</td>\n",
       "      <td>0.124319</td>\n",
       "      <td>0.051742</td>\n",
       "      <td>0.025810</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.044702</td>\n",
       "      <td>-0.081478</td>\n",
       "      <td>0.363194</td>\n",
       "      <td>0.028610</td>\n",
       "      <td>-0.001221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033292</td>\n",
       "      <td>0.016715</td>\n",
       "      <td>0.052470</td>\n",
       "      <td>-0.018523</td>\n",
       "      <td>-0.059272</td>\n",
       "      <td>0.064206</td>\n",
       "      <td>0.002180</td>\n",
       "      <td>-0.045785</td>\n",
       "      <td>0.020880</td>\n",
       "      <td>-0.008103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STK36</th>\n",
       "      <td>0.233974</td>\n",
       "      <td>-0.107774</td>\n",
       "      <td>-0.042366</td>\n",
       "      <td>0.048022</td>\n",
       "      <td>-0.199977</td>\n",
       "      <td>-0.128798</td>\n",
       "      <td>0.203723</td>\n",
       "      <td>-0.080470</td>\n",
       "      <td>0.017018</td>\n",
       "      <td>-0.043984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248172</td>\n",
       "      <td>-0.186951</td>\n",
       "      <td>-0.006909</td>\n",
       "      <td>-0.029808</td>\n",
       "      <td>-0.153021</td>\n",
       "      <td>-0.052863</td>\n",
       "      <td>-0.278905</td>\n",
       "      <td>-0.206194</td>\n",
       "      <td>-0.102138</td>\n",
       "      <td>-0.007806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CYBB</th>\n",
       "      <td>-0.332465</td>\n",
       "      <td>0.396785</td>\n",
       "      <td>0.029131</td>\n",
       "      <td>0.038733</td>\n",
       "      <td>0.596795</td>\n",
       "      <td>0.157724</td>\n",
       "      <td>-0.163636</td>\n",
       "      <td>0.071291</td>\n",
       "      <td>-0.074002</td>\n",
       "      <td>0.168935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697481</td>\n",
       "      <td>0.838581</td>\n",
       "      <td>-0.032007</td>\n",
       "      <td>-0.056376</td>\n",
       "      <td>0.470774</td>\n",
       "      <td>0.280029</td>\n",
       "      <td>0.885526</td>\n",
       "      <td>0.732831</td>\n",
       "      <td>0.014009</td>\n",
       "      <td>-0.043047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CALHM3</th>\n",
       "      <td>-0.051058</td>\n",
       "      <td>-0.007185</td>\n",
       "      <td>-0.009810</td>\n",
       "      <td>-0.004023</td>\n",
       "      <td>0.114201</td>\n",
       "      <td>-0.010395</td>\n",
       "      <td>-0.033062</td>\n",
       "      <td>0.293854</td>\n",
       "      <td>-0.004391</td>\n",
       "      <td>-0.009118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.087826</td>\n",
       "      <td>-0.004662</td>\n",
       "      <td>-0.006538</td>\n",
       "      <td>0.037994</td>\n",
       "      <td>-0.011721</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>-0.003912</td>\n",
       "      <td>0.033873</td>\n",
       "      <td>-0.005990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZNF542P</th>\n",
       "      <td>-0.126099</td>\n",
       "      <td>-0.156870</td>\n",
       "      <td>0.080381</td>\n",
       "      <td>0.094623</td>\n",
       "      <td>-0.051764</td>\n",
       "      <td>-0.050547</td>\n",
       "      <td>0.063813</td>\n",
       "      <td>-0.043351</td>\n",
       "      <td>0.103554</td>\n",
       "      <td>-0.024707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112823</td>\n",
       "      <td>0.011146</td>\n",
       "      <td>0.039838</td>\n",
       "      <td>-0.045167</td>\n",
       "      <td>-0.230159</td>\n",
       "      <td>0.010110</td>\n",
       "      <td>-0.100168</td>\n",
       "      <td>-0.172755</td>\n",
       "      <td>0.026590</td>\n",
       "      <td>0.089131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TNNI2</th>\n",
       "      <td>-0.053995</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>-0.007268</td>\n",
       "      <td>-0.003677</td>\n",
       "      <td>0.117293</td>\n",
       "      <td>-0.002775</td>\n",
       "      <td>-0.040844</td>\n",
       "      <td>0.288593</td>\n",
       "      <td>-0.010788</td>\n",
       "      <td>-0.014300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014533</td>\n",
       "      <td>0.098636</td>\n",
       "      <td>-0.002411</td>\n",
       "      <td>-0.008134</td>\n",
       "      <td>0.053991</td>\n",
       "      <td>0.011469</td>\n",
       "      <td>-0.000206</td>\n",
       "      <td>0.004851</td>\n",
       "      <td>0.030891</td>\n",
       "      <td>-0.007021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLRP6</th>\n",
       "      <td>-0.159986</td>\n",
       "      <td>0.225166</td>\n",
       "      <td>-0.032229</td>\n",
       "      <td>-0.049930</td>\n",
       "      <td>0.390904</td>\n",
       "      <td>0.038318</td>\n",
       "      <td>-0.034666</td>\n",
       "      <td>-0.017189</td>\n",
       "      <td>-0.028809</td>\n",
       "      <td>-0.057384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194452</td>\n",
       "      <td>0.376854</td>\n",
       "      <td>0.007056</td>\n",
       "      <td>-0.035717</td>\n",
       "      <td>0.314664</td>\n",
       "      <td>0.177957</td>\n",
       "      <td>0.393217</td>\n",
       "      <td>0.440565</td>\n",
       "      <td>0.029343</td>\n",
       "      <td>-0.028425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIRE</th>\n",
       "      <td>-0.150720</td>\n",
       "      <td>0.205064</td>\n",
       "      <td>-0.012723</td>\n",
       "      <td>0.023995</td>\n",
       "      <td>0.455971</td>\n",
       "      <td>-0.040099</td>\n",
       "      <td>-0.090398</td>\n",
       "      <td>0.086441</td>\n",
       "      <td>0.035783</td>\n",
       "      <td>-0.015490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.199168</td>\n",
       "      <td>0.025751</td>\n",
       "      <td>-0.009432</td>\n",
       "      <td>0.031991</td>\n",
       "      <td>0.033283</td>\n",
       "      <td>0.097585</td>\n",
       "      <td>0.198523</td>\n",
       "      <td>-0.024796</td>\n",
       "      <td>-0.007056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CXorf21</th>\n",
       "      <td>-0.350343</td>\n",
       "      <td>0.424573</td>\n",
       "      <td>-0.006048</td>\n",
       "      <td>0.071764</td>\n",
       "      <td>0.719525</td>\n",
       "      <td>0.193996</td>\n",
       "      <td>-0.177839</td>\n",
       "      <td>0.050747</td>\n",
       "      <td>-0.070406</td>\n",
       "      <td>0.042266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563553</td>\n",
       "      <td>0.783953</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>-0.058814</td>\n",
       "      <td>0.399322</td>\n",
       "      <td>0.271153</td>\n",
       "      <td>0.732162</td>\n",
       "      <td>0.686662</td>\n",
       "      <td>0.003015</td>\n",
       "      <td>-0.034060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEX35</th>\n",
       "      <td>0.090901</td>\n",
       "      <td>-0.155688</td>\n",
       "      <td>-0.048749</td>\n",
       "      <td>-0.032662</td>\n",
       "      <td>0.026608</td>\n",
       "      <td>-0.038535</td>\n",
       "      <td>0.172935</td>\n",
       "      <td>-0.076119</td>\n",
       "      <td>-0.004742</td>\n",
       "      <td>-0.064607</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075809</td>\n",
       "      <td>-0.041201</td>\n",
       "      <td>-0.021419</td>\n",
       "      <td>-0.028357</td>\n",
       "      <td>-0.074538</td>\n",
       "      <td>-0.048214</td>\n",
       "      <td>-0.067978</td>\n",
       "      <td>-0.074417</td>\n",
       "      <td>-0.020826</td>\n",
       "      <td>0.023114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIK3R2</th>\n",
       "      <td>0.339830</td>\n",
       "      <td>-0.322719</td>\n",
       "      <td>-0.088400</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>-0.352559</td>\n",
       "      <td>-0.123471</td>\n",
       "      <td>0.121523</td>\n",
       "      <td>-0.125147</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>-0.074667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266257</td>\n",
       "      <td>-0.365454</td>\n",
       "      <td>-0.022356</td>\n",
       "      <td>0.198218</td>\n",
       "      <td>-0.172011</td>\n",
       "      <td>-0.097257</td>\n",
       "      <td>-0.304718</td>\n",
       "      <td>-0.236842</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>0.018778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TLR4</th>\n",
       "      <td>-0.327254</td>\n",
       "      <td>0.294347</td>\n",
       "      <td>0.190332</td>\n",
       "      <td>0.102083</td>\n",
       "      <td>0.451407</td>\n",
       "      <td>0.180848</td>\n",
       "      <td>-0.158939</td>\n",
       "      <td>0.310082</td>\n",
       "      <td>-0.056937</td>\n",
       "      <td>0.049297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450675</td>\n",
       "      <td>0.585929</td>\n",
       "      <td>-0.041592</td>\n",
       "      <td>-0.060780</td>\n",
       "      <td>0.256465</td>\n",
       "      <td>0.307616</td>\n",
       "      <td>0.584090</td>\n",
       "      <td>0.447448</td>\n",
       "      <td>-0.020318</td>\n",
       "      <td>0.007923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCARNA11</th>\n",
       "      <td>0.049345</td>\n",
       "      <td>-0.025162</td>\n",
       "      <td>-0.019382</td>\n",
       "      <td>-0.020670</td>\n",
       "      <td>-0.002472</td>\n",
       "      <td>-0.058952</td>\n",
       "      <td>0.065904</td>\n",
       "      <td>-0.035202</td>\n",
       "      <td>-0.025502</td>\n",
       "      <td>-0.028693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003976</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.012272</td>\n",
       "      <td>-0.010450</td>\n",
       "      <td>0.145171</td>\n",
       "      <td>0.066966</td>\n",
       "      <td>0.005880</td>\n",
       "      <td>0.037831</td>\n",
       "      <td>-0.020180</td>\n",
       "      <td>-0.009538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCR1</th>\n",
       "      <td>-0.284266</td>\n",
       "      <td>0.463699</td>\n",
       "      <td>0.093686</td>\n",
       "      <td>-0.009401</td>\n",
       "      <td>0.344361</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>-0.178363</td>\n",
       "      <td>0.139425</td>\n",
       "      <td>-0.023807</td>\n",
       "      <td>0.159305</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733468</td>\n",
       "      <td>-0.034610</td>\n",
       "      <td>-0.062258</td>\n",
       "      <td>0.421850</td>\n",
       "      <td>0.347624</td>\n",
       "      <td>0.634328</td>\n",
       "      <td>0.584411</td>\n",
       "      <td>0.071765</td>\n",
       "      <td>-0.039156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLRC4</th>\n",
       "      <td>-0.334402</td>\n",
       "      <td>0.414166</td>\n",
       "      <td>0.102220</td>\n",
       "      <td>0.049155</td>\n",
       "      <td>0.531824</td>\n",
       "      <td>0.194335</td>\n",
       "      <td>-0.162994</td>\n",
       "      <td>0.101822</td>\n",
       "      <td>-0.028586</td>\n",
       "      <td>0.145501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.020290</td>\n",
       "      <td>-0.073937</td>\n",
       "      <td>0.445787</td>\n",
       "      <td>0.374284</td>\n",
       "      <td>0.730690</td>\n",
       "      <td>0.692756</td>\n",
       "      <td>0.081086</td>\n",
       "      <td>-0.047016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLC5A5</th>\n",
       "      <td>-0.048202</td>\n",
       "      <td>-0.028920</td>\n",
       "      <td>-0.011633</td>\n",
       "      <td>0.366437</td>\n",
       "      <td>-0.019463</td>\n",
       "      <td>-0.013907</td>\n",
       "      <td>-0.045696</td>\n",
       "      <td>-0.007522</td>\n",
       "      <td>-0.011586</td>\n",
       "      <td>-0.002946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034610</td>\n",
       "      <td>-0.020290</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006158</td>\n",
       "      <td>0.014619</td>\n",
       "      <td>-0.022380</td>\n",
       "      <td>-0.026785</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>0.008992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPPED1</th>\n",
       "      <td>0.019921</td>\n",
       "      <td>-0.069754</td>\n",
       "      <td>-0.010444</td>\n",
       "      <td>-0.009141</td>\n",
       "      <td>-0.071125</td>\n",
       "      <td>-0.025520</td>\n",
       "      <td>0.045716</td>\n",
       "      <td>-0.020715</td>\n",
       "      <td>-0.011767</td>\n",
       "      <td>-0.014481</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062258</td>\n",
       "      <td>-0.073937</td>\n",
       "      <td>-0.006158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.061112</td>\n",
       "      <td>-0.043014</td>\n",
       "      <td>-0.054038</td>\n",
       "      <td>-0.048701</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>-0.004862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HLA-B</th>\n",
       "      <td>-0.165554</td>\n",
       "      <td>0.227420</td>\n",
       "      <td>-0.001873</td>\n",
       "      <td>-0.040732</td>\n",
       "      <td>0.355716</td>\n",
       "      <td>0.071370</td>\n",
       "      <td>-0.010572</td>\n",
       "      <td>-0.010833</td>\n",
       "      <td>-0.070753</td>\n",
       "      <td>0.066510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421850</td>\n",
       "      <td>0.445787</td>\n",
       "      <td>0.014619</td>\n",
       "      <td>-0.061112</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.260638</td>\n",
       "      <td>0.459234</td>\n",
       "      <td>0.789938</td>\n",
       "      <td>0.019240</td>\n",
       "      <td>-0.043146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TBXAS1</th>\n",
       "      <td>-0.103870</td>\n",
       "      <td>0.296426</td>\n",
       "      <td>0.116505</td>\n",
       "      <td>-0.020897</td>\n",
       "      <td>0.121938</td>\n",
       "      <td>0.154639</td>\n",
       "      <td>-0.164143</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.094177</td>\n",
       "      <td>0.032749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347624</td>\n",
       "      <td>0.374284</td>\n",
       "      <td>-0.022380</td>\n",
       "      <td>-0.043014</td>\n",
       "      <td>0.260638</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.246296</td>\n",
       "      <td>0.356233</td>\n",
       "      <td>0.024875</td>\n",
       "      <td>-0.039367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPR141</th>\n",
       "      <td>-0.292375</td>\n",
       "      <td>0.400492</td>\n",
       "      <td>0.027690</td>\n",
       "      <td>0.046167</td>\n",
       "      <td>0.509011</td>\n",
       "      <td>0.145470</td>\n",
       "      <td>-0.123003</td>\n",
       "      <td>0.034162</td>\n",
       "      <td>-0.066088</td>\n",
       "      <td>0.116464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634328</td>\n",
       "      <td>0.730690</td>\n",
       "      <td>-0.026785</td>\n",
       "      <td>-0.054038</td>\n",
       "      <td>0.459234</td>\n",
       "      <td>0.246296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.692169</td>\n",
       "      <td>0.038125</td>\n",
       "      <td>-0.047164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HLA-DRA</th>\n",
       "      <td>-0.257832</td>\n",
       "      <td>0.313661</td>\n",
       "      <td>-0.039828</td>\n",
       "      <td>-0.004245</td>\n",
       "      <td>0.512637</td>\n",
       "      <td>0.117725</td>\n",
       "      <td>-0.113595</td>\n",
       "      <td>-0.047295</td>\n",
       "      <td>-0.047351</td>\n",
       "      <td>0.067687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584411</td>\n",
       "      <td>0.692756</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.048701</td>\n",
       "      <td>0.789938</td>\n",
       "      <td>0.356233</td>\n",
       "      <td>0.692169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028340</td>\n",
       "      <td>-0.037835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CES1P1</th>\n",
       "      <td>-0.037957</td>\n",
       "      <td>-0.025722</td>\n",
       "      <td>-0.018013</td>\n",
       "      <td>0.009113</td>\n",
       "      <td>0.070306</td>\n",
       "      <td>0.053181</td>\n",
       "      <td>-0.030331</td>\n",
       "      <td>0.140210</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071765</td>\n",
       "      <td>0.081086</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>0.019240</td>\n",
       "      <td>0.024875</td>\n",
       "      <td>0.038125</td>\n",
       "      <td>0.028340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCNAP1</th>\n",
       "      <td>-0.046990</td>\n",
       "      <td>0.060322</td>\n",
       "      <td>-0.009153</td>\n",
       "      <td>-0.004106</td>\n",
       "      <td>-0.048723</td>\n",
       "      <td>-0.015888</td>\n",
       "      <td>0.130307</td>\n",
       "      <td>-0.015806</td>\n",
       "      <td>-0.011676</td>\n",
       "      <td>-0.013585</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039156</td>\n",
       "      <td>-0.047016</td>\n",
       "      <td>0.008992</td>\n",
       "      <td>-0.004862</td>\n",
       "      <td>-0.043146</td>\n",
       "      <td>-0.039367</td>\n",
       "      <td>-0.047164</td>\n",
       "      <td>-0.037835</td>\n",
       "      <td>-0.009830</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ACY1     WIPF1       HGF    ADGRA1     PLCL2   COL10A1  \\\n",
       "ACY1       1.000000 -0.204649 -0.022824 -0.020961 -0.349030 -0.134046   \n",
       "WIPF1     -0.204649  1.000000  0.234293 -0.034678  0.296577  0.056953   \n",
       "HGF       -0.022824  0.234293  1.000000 -0.014601 -0.055203  0.045808   \n",
       "ADGRA1    -0.020961 -0.034678 -0.014601  1.000000  0.098894  0.012882   \n",
       "PLCL2     -0.349030  0.296577 -0.055203  0.098894  1.000000  0.081274   \n",
       "COL10A1   -0.134046  0.056953  0.045808  0.012882  0.081274  1.000000   \n",
       "HIST1H2AM  0.287491 -0.167969 -0.006186  0.046039 -0.163540 -0.156296   \n",
       "RFX8      -0.139039  0.184788  0.299265 -0.018780  0.083205  0.274167   \n",
       "HTR5A     -0.054540 -0.025678  0.000705  0.051725 -0.064729 -0.029997   \n",
       "CXCL6     -0.056513  0.085137  0.092573 -0.019164 -0.023362  0.160042   \n",
       "CDK2       0.317515 -0.306191 -0.111271 -0.070078 -0.215249 -0.149692   \n",
       "PMEL       0.452402 -0.285077 -0.104135 -0.043964 -0.271479 -0.127885   \n",
       "OR2M4     -0.115802  0.263896  0.394022 -0.023728  0.123088  0.025771   \n",
       "SPRED3    -0.137780  0.346872  0.539141 -0.037198 -0.039463  0.134718   \n",
       "HLA-DOA   -0.223811  0.259146 -0.034771 -0.001138  0.448426  0.044411   \n",
       "NTM       -0.192422  0.284010  0.131434 -0.022980  0.035313  0.114953   \n",
       "NANOG     -0.086761 -0.046270  0.016595  0.012342 -0.017363 -0.024822   \n",
       "POM121L4P  0.006662  0.111346  0.027602 -0.008127  0.140562  0.133349   \n",
       "PLXDC2    -0.309935  0.326517  0.127333  0.188833  0.334190  0.473467   \n",
       "GPR82     -0.254121  0.384940  0.110756  0.034297  0.482105  0.041146   \n",
       "PPP1R14C  -0.095201  0.094191 -0.051668 -0.048721 -0.072819 -0.032061   \n",
       "ALPL      -0.002692  0.085826 -0.012189 -0.005562  0.145346  0.088378   \n",
       "ANKRD30A  -0.053467 -0.041122 -0.007231 -0.012530 -0.051412 -0.057609   \n",
       "FAM69B     0.468095 -0.403295 -0.133771 -0.000158 -0.297142 -0.173547   \n",
       "PSD        0.163318  0.021492  0.036035  0.076843 -0.100160  0.043219   \n",
       "TBC1D16    0.322266 -0.311996 -0.100576 -0.046676 -0.241435 -0.119672   \n",
       "EDARADD   -0.112585  0.012914 -0.052071  0.006835  0.086595  0.036174   \n",
       "WNT9A     -0.110394  0.124319  0.051742  0.025810  0.015656  0.044702   \n",
       "STK36      0.233974 -0.107774 -0.042366  0.048022 -0.199977 -0.128798   \n",
       "CYBB      -0.332465  0.396785  0.029131  0.038733  0.596795  0.157724   \n",
       "CALHM3    -0.051058 -0.007185 -0.009810 -0.004023  0.114201 -0.010395   \n",
       "ZNF542P   -0.126099 -0.156870  0.080381  0.094623 -0.051764 -0.050547   \n",
       "TNNI2     -0.053995  0.001892 -0.007268 -0.003677  0.117293 -0.002775   \n",
       "NLRP6     -0.159986  0.225166 -0.032229 -0.049930  0.390904  0.038318   \n",
       "AIRE      -0.150720  0.205064 -0.012723  0.023995  0.455971 -0.040099   \n",
       "CXorf21   -0.350343  0.424573 -0.006048  0.071764  0.719525  0.193996   \n",
       "TEX35      0.090901 -0.155688 -0.048749 -0.032662  0.026608 -0.038535   \n",
       "PIK3R2     0.339830 -0.322719 -0.088400  0.008100 -0.352559 -0.123471   \n",
       "TLR4      -0.327254  0.294347  0.190332  0.102083  0.451407  0.180848   \n",
       "SCARNA11   0.049345 -0.025162 -0.019382 -0.020670 -0.002472 -0.058952   \n",
       "CCR1      -0.284266  0.463699  0.093686 -0.009401  0.344361  0.231700   \n",
       "NLRC4     -0.334402  0.414166  0.102220  0.049155  0.531824  0.194335   \n",
       "SLC5A5    -0.048202 -0.028920 -0.011633  0.366437 -0.019463 -0.013907   \n",
       "MPPED1     0.019921 -0.069754 -0.010444 -0.009141 -0.071125 -0.025520   \n",
       "HLA-B     -0.165554  0.227420 -0.001873 -0.040732  0.355716  0.071370   \n",
       "TBXAS1    -0.103870  0.296426  0.116505 -0.020897  0.121938  0.154639   \n",
       "GPR141    -0.292375  0.400492  0.027690  0.046167  0.509011  0.145470   \n",
       "HLA-DRA   -0.257832  0.313661 -0.039828 -0.004245  0.512637  0.117725   \n",
       "CES1P1    -0.037957 -0.025722 -0.018013  0.009113  0.070306  0.053181   \n",
       "PCNAP1    -0.046990  0.060322 -0.009153 -0.004106 -0.048723 -0.015888   \n",
       "\n",
       "           HIST1H2AM      RFX8     HTR5A     CXCL6  ...      CCR1     NLRC4  \\\n",
       "ACY1        0.287491 -0.139039 -0.054540 -0.056513  ... -0.284266 -0.334402   \n",
       "WIPF1      -0.167969  0.184788 -0.025678  0.085137  ...  0.463699  0.414166   \n",
       "HGF        -0.006186  0.299265  0.000705  0.092573  ...  0.093686  0.102220   \n",
       "ADGRA1      0.046039 -0.018780  0.051725 -0.019164  ... -0.009401  0.049155   \n",
       "PLCL2      -0.163540  0.083205 -0.064729 -0.023362  ...  0.344361  0.531824   \n",
       "COL10A1    -0.156296  0.274167 -0.029997  0.160042  ...  0.231700  0.194335   \n",
       "HIST1H2AM   1.000000 -0.129061  0.059908  0.020767  ... -0.178363 -0.162994   \n",
       "RFX8       -0.129061  1.000000  0.001089  0.036186  ...  0.139425  0.101822   \n",
       "HTR5A       0.059908  0.001089  1.000000  0.015236  ... -0.023807 -0.028586   \n",
       "CXCL6       0.020767  0.036186  0.015236  1.000000  ...  0.159305  0.145501   \n",
       "CDK2        0.142863 -0.229001 -0.058021 -0.090999  ... -0.302146 -0.348398   \n",
       "PMEL        0.170178 -0.195535 -0.058973 -0.100009  ... -0.268332 -0.355681   \n",
       "OR2M4      -0.090239  0.380518 -0.034260  0.029189  ...  0.126688  0.167923   \n",
       "SPRED3     -0.107959  0.535268  0.042052  0.174183  ...  0.110237  0.067319   \n",
       "HLA-DOA    -0.087345 -0.041454 -0.040207  0.015432  ...  0.407114  0.492460   \n",
       "NTM        -0.150809  0.311891 -0.026912  0.052455  ...  0.146216  0.138594   \n",
       "NANOG       0.009193 -0.016863  0.307958 -0.011745  ... -0.046468  0.026469   \n",
       "POM121L4P  -0.030035  0.037658  0.053486 -0.039957  ...  0.019603  0.126414   \n",
       "PLXDC2     -0.216400  0.145244 -0.053502  0.066001  ...  0.574861  0.610265   \n",
       "GPR82      -0.170199  0.045652 -0.055755  0.089757  ...  0.445192  0.574343   \n",
       "PPP1R14C   -0.018855 -0.044516 -0.044988 -0.007662  ...  0.091430 -0.016702   \n",
       "ALPL       -0.053117  0.216934 -0.033577  0.093984  ...  0.196258  0.261393   \n",
       "ANKRD30A    0.047503  0.009607  0.678646  0.037062  ... -0.089345 -0.063983   \n",
       "FAM69B      0.142798 -0.236524 -0.005700 -0.104368  ... -0.330471 -0.352998   \n",
       "PSD         0.025857  0.076217  0.092214  0.215177  ...  0.012171  0.079027   \n",
       "TBC1D16     0.308000 -0.189544 -0.044427 -0.106282  ... -0.308345 -0.376941   \n",
       "EDARADD     0.020692  0.006062  0.188596 -0.015316  ...  0.081897  0.080870   \n",
       "WNT9A      -0.081478  0.363194  0.028610 -0.001221  ...  0.033292  0.016715   \n",
       "STK36       0.203723 -0.080470  0.017018 -0.043984  ... -0.248172 -0.186951   \n",
       "CYBB       -0.163636  0.071291 -0.074002  0.168935  ...  0.697481  0.838581   \n",
       "CALHM3     -0.033062  0.293854 -0.004391 -0.009118  ...  0.002221  0.087826   \n",
       "ZNF542P     0.063813 -0.043351  0.103554 -0.024707  ... -0.112823  0.011146   \n",
       "TNNI2      -0.040844  0.288593 -0.010788 -0.014300  ...  0.014533  0.098636   \n",
       "NLRP6      -0.034666 -0.017189 -0.028809 -0.057384  ...  0.194452  0.376854   \n",
       "AIRE       -0.090398  0.086441  0.035783 -0.015490  ...  0.002006  0.199168   \n",
       "CXorf21    -0.177839  0.050747 -0.070406  0.042266  ...  0.563553  0.783953   \n",
       "TEX35       0.172935 -0.076119 -0.004742 -0.064607  ... -0.075809 -0.041201   \n",
       "PIK3R2      0.121523 -0.125147  0.003115 -0.074667  ... -0.266257 -0.365454   \n",
       "TLR4       -0.158939  0.310082 -0.056937  0.049297  ...  0.450675  0.585929   \n",
       "SCARNA11    0.065904 -0.035202 -0.025502 -0.028693  ...  0.003976 -0.000086   \n",
       "CCR1       -0.178363  0.139425 -0.023807  0.159305  ...  1.000000  0.733468   \n",
       "NLRC4      -0.162994  0.101822 -0.028586  0.145501  ...  0.733468  1.000000   \n",
       "SLC5A5     -0.045696 -0.007522 -0.011586 -0.002946  ... -0.034610 -0.020290   \n",
       "MPPED1      0.045716 -0.020715 -0.011767 -0.014481  ... -0.062258 -0.073937   \n",
       "HLA-B      -0.010572 -0.010833 -0.070753  0.066510  ...  0.421850  0.445787   \n",
       "TBXAS1     -0.164143  0.035533  0.094177  0.032749  ...  0.347624  0.374284   \n",
       "GPR141     -0.123003  0.034162 -0.066088  0.116464  ...  0.634328  0.730690   \n",
       "HLA-DRA    -0.113595 -0.047295 -0.047351  0.067687  ...  0.584411  0.692756   \n",
       "CES1P1     -0.030331  0.140210 -0.010001  0.008475  ...  0.071765  0.081086   \n",
       "PCNAP1      0.130307 -0.015806 -0.011676 -0.013585  ... -0.039156 -0.047016   \n",
       "\n",
       "             SLC5A5    MPPED1     HLA-B    TBXAS1    GPR141   HLA-DRA  \\\n",
       "ACY1      -0.048202  0.019921 -0.165554 -0.103870 -0.292375 -0.257832   \n",
       "WIPF1     -0.028920 -0.069754  0.227420  0.296426  0.400492  0.313661   \n",
       "HGF       -0.011633 -0.010444 -0.001873  0.116505  0.027690 -0.039828   \n",
       "ADGRA1     0.366437 -0.009141 -0.040732 -0.020897  0.046167 -0.004245   \n",
       "PLCL2     -0.019463 -0.071125  0.355716  0.121938  0.509011  0.512637   \n",
       "COL10A1   -0.013907 -0.025520  0.071370  0.154639  0.145470  0.117725   \n",
       "HIST1H2AM -0.045696  0.045716 -0.010572 -0.164143 -0.123003 -0.113595   \n",
       "RFX8      -0.007522 -0.020715 -0.010833  0.035533  0.034162 -0.047295   \n",
       "HTR5A     -0.011586 -0.011767 -0.070753  0.094177 -0.066088 -0.047351   \n",
       "CXCL6     -0.002946 -0.014481  0.066510  0.032749  0.116464  0.067687   \n",
       "CDK2      -0.067768 -0.010944 -0.159081 -0.281088 -0.198010 -0.161399   \n",
       "PMEL      -0.041892  0.011129 -0.165733 -0.229864 -0.224307 -0.189147   \n",
       "OR2M4     -0.013204 -0.014948  0.014752  0.073770  0.096073  0.129354   \n",
       "SPRED3    -0.020554 -0.028614 -0.016770  0.216678  0.029301 -0.078761   \n",
       "HLA-DOA   -0.013044 -0.035128  0.668090  0.249526  0.546210  0.834231   \n",
       "NTM       -0.020476 -0.016045 -0.023799  0.120416  0.104975  0.039516   \n",
       "NANOG     -0.009892 -0.007865 -0.073193 -0.005478 -0.044624 -0.044738   \n",
       "POM121L4P -0.013826 -0.029827  0.094886  0.055685  0.115600  0.130344   \n",
       "PLXDC2    -0.010848 -0.056813  0.226467  0.312605  0.565559  0.497645   \n",
       "GPR82     -0.025831 -0.046739  0.224765  0.268023  0.542670  0.461570   \n",
       "PPP1R14C  -0.032938 -0.029927  0.062120  0.004431 -0.000628  0.032739   \n",
       "ALPL       0.003039 -0.026415  0.129588  0.185408  0.150852  0.180628   \n",
       "ANKRD30A  -0.012291 -0.004990 -0.069762  0.026521 -0.085791 -0.098970   \n",
       "FAM69B    -0.019102  0.075919 -0.187458 -0.202578 -0.285105 -0.227035   \n",
       "PSD       -0.024800 -0.035374 -0.053335  0.106785 -0.068882 -0.026245   \n",
       "TBC1D16   -0.040195  0.104095 -0.178263 -0.223512 -0.261106 -0.221512   \n",
       "EDARADD   -0.041182 -0.028766  0.176052  0.041992  0.129936  0.161213   \n",
       "WNT9A      0.052470 -0.018523 -0.059272  0.064206  0.002180 -0.045785   \n",
       "STK36     -0.006909 -0.029808 -0.153021 -0.052863 -0.278905 -0.206194   \n",
       "CYBB      -0.032007 -0.056376  0.470774  0.280029  0.885526  0.732831   \n",
       "CALHM3    -0.004662 -0.006538  0.037994 -0.011721 -0.001900 -0.003912   \n",
       "ZNF542P    0.039838 -0.045167 -0.230159  0.010110 -0.100168 -0.172755   \n",
       "TNNI2     -0.002411 -0.008134  0.053991  0.011469 -0.000206  0.004851   \n",
       "NLRP6      0.007056 -0.035717  0.314664  0.177957  0.393217  0.440565   \n",
       "AIRE       0.025751 -0.009432  0.031991  0.033283  0.097585  0.198523   \n",
       "CXorf21   -0.006616 -0.058814  0.399322  0.271153  0.732162  0.686662   \n",
       "TEX35     -0.021419 -0.028357 -0.074538 -0.048214 -0.067978 -0.074417   \n",
       "PIK3R2    -0.022356  0.198218 -0.172011 -0.097257 -0.304718 -0.236842   \n",
       "TLR4      -0.041592 -0.060780  0.256465  0.307616  0.584090  0.447448   \n",
       "SCARNA11  -0.012272 -0.010450  0.145171  0.066966  0.005880  0.037831   \n",
       "CCR1      -0.034610 -0.062258  0.421850  0.347624  0.634328  0.584411   \n",
       "NLRC4     -0.020290 -0.073937  0.445787  0.374284  0.730690  0.692756   \n",
       "SLC5A5     1.000000 -0.006158  0.014619 -0.022380 -0.026785 -0.000038   \n",
       "MPPED1    -0.006158  1.000000 -0.061112 -0.043014 -0.054038 -0.048701   \n",
       "HLA-B      0.014619 -0.061112  1.000000  0.260638  0.459234  0.789938   \n",
       "TBXAS1    -0.022380 -0.043014  0.260638  1.000000  0.246296  0.356233   \n",
       "GPR141    -0.026785 -0.054038  0.459234  0.246296  1.000000  0.692169   \n",
       "HLA-DRA   -0.000038 -0.048701  0.789938  0.356233  0.692169  1.000000   \n",
       "CES1P1     0.008113  0.003452  0.019240  0.024875  0.038125  0.028340   \n",
       "PCNAP1     0.008992 -0.004862 -0.043146 -0.039367 -0.047164 -0.037835   \n",
       "\n",
       "             CES1P1    PCNAP1  \n",
       "ACY1      -0.037957 -0.046990  \n",
       "WIPF1     -0.025722  0.060322  \n",
       "HGF       -0.018013 -0.009153  \n",
       "ADGRA1     0.009113 -0.004106  \n",
       "PLCL2      0.070306 -0.048723  \n",
       "COL10A1    0.053181 -0.015888  \n",
       "HIST1H2AM -0.030331  0.130307  \n",
       "RFX8       0.140210 -0.015806  \n",
       "HTR5A     -0.010001 -0.011676  \n",
       "CXCL6      0.008475 -0.013585  \n",
       "CDK2      -0.077708 -0.000058  \n",
       "PMEL      -0.050997 -0.005889  \n",
       "OR2M4     -0.023650 -0.013769  \n",
       "SPRED3     0.015697 -0.023327  \n",
       "HLA-DOA   -0.001139 -0.031600  \n",
       "NTM        0.067430 -0.021332  \n",
       "NANOG     -0.008928 -0.007990  \n",
       "POM121L4P  0.002754 -0.028463  \n",
       "PLXDC2     0.103824 -0.034441  \n",
       "GPR82     -0.034771 -0.003683  \n",
       "PPP1R14C   0.004600 -0.027272  \n",
       "ALPL       0.130078 -0.020905  \n",
       "ANKRD30A   0.122022 -0.010709  \n",
       "FAM69B    -0.087145  0.112603  \n",
       "PSD        0.104854 -0.019590  \n",
       "TBC1D16   -0.064847  0.092782  \n",
       "EDARADD    0.023419  0.024078  \n",
       "WNT9A      0.020880 -0.008103  \n",
       "STK36     -0.102138 -0.007806  \n",
       "CYBB       0.014009 -0.043047  \n",
       "CALHM3     0.033873 -0.005990  \n",
       "ZNF542P    0.026590  0.089131  \n",
       "TNNI2      0.030891 -0.007021  \n",
       "NLRP6      0.029343 -0.028425  \n",
       "AIRE      -0.024796 -0.007056  \n",
       "CXorf21    0.003015 -0.034060  \n",
       "TEX35     -0.020826  0.023114  \n",
       "PIK3R2     0.004573  0.018778  \n",
       "TLR4      -0.020318  0.007923  \n",
       "SCARNA11  -0.020180 -0.009538  \n",
       "CCR1       0.071765 -0.039156  \n",
       "NLRC4      0.081086 -0.047016  \n",
       "SLC5A5     0.008113  0.008992  \n",
       "MPPED1     0.003452 -0.004862  \n",
       "HLA-B      0.019240 -0.043146  \n",
       "TBXAS1     0.024875 -0.039367  \n",
       "GPR141     0.038125 -0.047164  \n",
       "HLA-DRA    0.028340 -0.037835  \n",
       "CES1P1     1.000000 -0.009830  \n",
       "PCNAP1    -0.009830  1.000000  \n",
       "\n",
       "[50 rows x 50 columns]"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 40\n",
    "np.fill_diagonal(adj_corr.values, 0)\n",
    "flatten_corr_adj = adj_corr.values.flatten()\n",
    "sorted_indices = np.argsort(flatten_corr_adj)[::-1]\n",
    "top_K_indices = sorted_indices[:K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_indices, col_indices = np.unravel_index(top_K_indices, adj_corr.shape)\n",
    "selected_edges = [[row, col] for row, col in zip(row_indices, col_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TCGA-D3-A3CE', 'TCGA-FR-A729', 'TCGA-D3-A3CF', 'TCGA-D3-A3CC',\n",
       "       'TCGA-GN-A8LL', 'TCGA-GN-A8LK', 'TCGA-FS-A1ZS', 'TCGA-ER-A42K',\n",
       "       'TCGA-EE-A3JI', 'TCGA-EE-A3JH',\n",
       "       ...\n",
       "       'TCGA-FS-A1Z4', 'TCGA-D3-A3ML', 'TCGA-WE-A8K5', 'TCGA-EE-A2M5',\n",
       "       'TCGA-D3-A5GL', 'TCGA-EE-A2M7', 'TCGA-EE-A2M6', 'TCGA-D9-A3Z1',\n",
       "       'TCGA-EE-A3AF', 'TCGA-EE-A2M8'],\n",
       "      dtype='object', length=230)"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "data_list = []\n",
    "for i in range(len(sample_ids)):\n",
    "    data = Data(x=node_features[i].unsqueeze(1), edge_index=torch.tensor(selected_edges, dtype=torch.long).T, y=graph_labels[i], sample_id=sample_ids[i])\n",
    "    data_list.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[30, 32, 46, 29, 41, 29, 47, 14, 35, 29, 11, 10, 44, 47, 41, 35, 32, 21,\n",
       "         30, 21, 40, 41, 47, 29, 46, 35, 46, 41, 35,  4, 29, 40, 19, 35, 41, 47,\n",
       "         46, 47, 47, 35],\n",
       "        [32, 30, 29, 46, 29, 41, 14, 47, 29, 35, 10, 11, 47, 44, 35, 41, 21, 32,\n",
       "         21, 30, 41, 40, 29, 47, 35, 46, 41, 46,  4, 35, 40, 29, 35, 19, 47, 41,\n",
       "         47, 46, 35, 47]])"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor(edge_index, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4431])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_labels = torch.tensor(y.values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids = im.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene1</th>\n",
       "      <th>gene2</th>\n",
       "      <th>sampleID</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22361</th>\n",
       "      <td>CYBB</td>\n",
       "      <td>CXorf21</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>6.459650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22376</th>\n",
       "      <td>CYBB</td>\n",
       "      <td>TLR4</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>5.111221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22379</th>\n",
       "      <td>CYBB</td>\n",
       "      <td>CCR1</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>4.030512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22385</th>\n",
       "      <td>CYBB</td>\n",
       "      <td>NLRC4</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>5.245081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24142</th>\n",
       "      <td>CXorf21</td>\n",
       "      <td>TLR4</td>\n",
       "      <td>TCGA-D3-A3CE</td>\n",
       "      <td>4.030512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7656472</th>\n",
       "      <td>NLRC4</td>\n",
       "      <td>HLA-DRA</td>\n",
       "      <td>TCGA-EE-A2M8</td>\n",
       "      <td>8.000349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7657484</th>\n",
       "      <td>HLA-B</td>\n",
       "      <td>TBXAS1</td>\n",
       "      <td>TCGA-EE-A2M8</td>\n",
       "      <td>2.353183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7657487</th>\n",
       "      <td>HLA-B</td>\n",
       "      <td>GPR141</td>\n",
       "      <td>TCGA-EE-A2M8</td>\n",
       "      <td>5.451294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7657497</th>\n",
       "      <td>HLA-B</td>\n",
       "      <td>HLA-DRA</td>\n",
       "      <td>TCGA-EE-A2M8</td>\n",
       "      <td>9.597622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7658013</th>\n",
       "      <td>GPR141</td>\n",
       "      <td>HLA-DRA</td>\n",
       "      <td>TCGA-EE-A2M8</td>\n",
       "      <td>6.652325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4431 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           gene1    gene2      sampleID     value\n",
       "22361       CYBB  CXorf21  TCGA-D3-A3CE  6.459650\n",
       "22376       CYBB     TLR4  TCGA-D3-A3CE  5.111221\n",
       "22379       CYBB     CCR1  TCGA-D3-A3CE  4.030512\n",
       "22385       CYBB    NLRC4  TCGA-D3-A3CE  5.245081\n",
       "24142    CXorf21     TLR4  TCGA-D3-A3CE  4.030512\n",
       "...          ...      ...           ...       ...\n",
       "7656472    NLRC4  HLA-DRA  TCGA-EE-A2M8  8.000349\n",
       "7657484    HLA-B   TBXAS1  TCGA-EE-A2M8  2.353183\n",
       "7657487    HLA-B   GPR141  TCGA-EE-A2M8  5.451294\n",
       "7657497    HLA-B  HLA-DRA  TCGA-EE-A2M8  9.597622\n",
       "7658013   GPR141  HLA-DRA  TCGA-EE-A2M8  6.652325\n",
       "\n",
       "[4431 rows x 4 columns]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_indexes_selected_by_sample_and_gene1_and_gene2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TCGA-D3-A3CE', 'TCGA-FR-A729', 'TCGA-D3-A3CF', 'TCGA-D3-A3CC',\n",
       "       'TCGA-GN-A8LL', 'TCGA-GN-A8LK', 'TCGA-FS-A1ZS', 'TCGA-ER-A42K',\n",
       "       'TCGA-EE-A3JI', 'TCGA-EE-A3JH',\n",
       "       ...\n",
       "       'TCGA-FS-A1Z4', 'TCGA-D3-A3ML', 'TCGA-WE-A8K5', 'TCGA-EE-A2M5',\n",
       "       'TCGA-D3-A5GL', 'TCGA-EE-A2M7', 'TCGA-EE-A2M6', 'TCGA-D9-A3Z1',\n",
       "       'TCGA-EE-A3AF', 'TCGA-EE-A2M8'],\n",
       "      dtype='object', length=230)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = edge_indexes_selected_by_sample_and_gene1_and_gene2['sampleID'].map(lambda x: sample_ids.get_loc(x)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = torch.tensor(X_new, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features[0].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4431,)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [1100] at index 0 does not match the shape of the indexed tensor [55000, 2] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/share/home/zhangqibin/CIDER/immune_mlp.ipynb Cell 80\u001b[0m in \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bg02/share/home/zhangqibin/CIDER/immune_mlp.ipynb#Y120sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m data_list \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bg02/share/home/zhangqibin/CIDER/immune_mlp.ipynb#Y120sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(sample_ids)):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bg02/share/home/zhangqibin/CIDER/immune_mlp.ipynb#Y120sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     data \u001b[39m=\u001b[39m Data(x\u001b[39m=\u001b[39mnode_features[i]\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m), edge_index\u001b[39m=\u001b[39medge_index\u001b[39m.\u001b[39;49mT[batch \u001b[39m==\u001b[39;49m i]\u001b[39m.\u001b[39mT, y\u001b[39m=\u001b[39mgraph_labels[i], sample_id\u001b[39m=\u001b[39msample_ids[i])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bg02/share/home/zhangqibin/CIDER/immune_mlp.ipynb#Y120sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     data_list\u001b[39m.\u001b[39mappend(data)\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [1100] at index 0 does not match the shape of the indexed tensor [55000, 2] at index 0"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "data_list = []\n",
    "for i in range(len(sample_ids)):\n",
    "    data = Data(x=node_features[i].unsqueeze(1), edge_index=edge_index.T[batch == i].T, y=graph_labels[i], sample_id=sample_ids[i])\n",
    "    data_list.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset, DataLoader\n",
    "\n",
    "# Custom Dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.data_list = data_list\n",
    "    \n",
    "    def len(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def get(self, index):\n",
    "        return self.data_list[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-D9-A3Z1'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-FS-A1ZY'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A3J5'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A3J8'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-W3-AA1R'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-FS-A1ZA'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A8GL'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-D3-A2J9'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-ER-A1A1'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-ER-A42K'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A29G'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A1QB'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2MS'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A5GL'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A3AF'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A2M7'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-FS-A1ZZ'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-GN-A26D'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-W3-A824'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A2GR'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-W3-AA1Q'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-WE-A8ZO'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A20F'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-DA-A1I0'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A2JG'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2MC'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A1Q6'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-ER-A199'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-W3-A828'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-D3-A1Q3'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A20C'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-ER-A2NG'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-FS-A4F8'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A51J'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-FS-A1ZB'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2MT'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-WE-A8ZR'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-3N-A9WD'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-FS-A1Z7'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A2MH'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2ML'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A182'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-DA-A1I8'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A8GS'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-Z2-AA3S'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D9-A6EC'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-ER-A42L'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-FR-A8YC'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A2A5'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A8GR'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-ER-A19J'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-DA-A1I2'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A5GO'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-FR-A3YN'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-GN-A9SD'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-D3-A1Q9'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A3J3'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-GN-A4U7'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A3JB'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A29X'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2GL'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-FS-A4FD'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-FS-A1ZJ'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-GN-A268'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-FS-A1Z0'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-FS-A1YX'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A3AD'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-D3-A3MO'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-FS-A1YW'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-DA-A1I4'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-DA-A3F3'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A5GN'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A2J8'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A180'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-DA-A1I7'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-WE-A8K5'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-D3-A2JK'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EB-A5KH'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A183'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-DA-A1IC'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-D9-A4Z6'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-GN-A4U3'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-FS-A1ZP'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-GN-A26A'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-QB-AA9O'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A184'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-FS-A1ZM'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-FS-A4F5'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A8GC'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A3JA'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-DA-A1I5'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-FS-A4F2'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A5GU'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A29L'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A29C'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-FS-A1ZE'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-D3-A1Q1'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2GS'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A3AB'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-FS-A1YY'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-W3-AA1W'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2A1'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-ER-A19C'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A29A'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-D3-A1Q8'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-ER-A2NE'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-DA-A1IA'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2MF'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A3C6'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-DA-A3F2'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A29V'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A3CE'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-DA-A95Y'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2MQ'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A8GJ'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-ER-A19E'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A8GP'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2MK'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2MN'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-FR-A729'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-FS-A1ZH'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A29D'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-GN-A8LL'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A29B'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A2JN'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-D3-A3CF'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-FR-A44A'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-FS-A1Z4'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-DA-A1I1'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-D3-A3ML'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-D3-A2JD'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-GN-A267'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-DA-A95V'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A20I'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2GU'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A17Y'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-ER-A2ND'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2M6'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-W3-AA1V'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2A6'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-GN-A8LK'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2MI'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2MD'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2ME'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2MG'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-FS-A1ZD'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A2GP'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A2JB'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A3AH'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-FS-A1ZS'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A2J7'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A2JA'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-DA-A3F5'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2MP'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-ER-A197'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-ER-A193'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A29W'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-ER-A19A'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-W3-A825'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-D3-A2JE'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-ER-A2NC'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A29S'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A2JC'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2MJ'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2GO'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-DA-A1HY'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A1Q7'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A2J6'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-FS-A1ZU'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A3AG'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A3CC'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-FS-A1Z3'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A20B'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-DA-A95X'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A181'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-FS-A1ZF'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-FS-A1ZR'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-ER-A19M'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2GM'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A3JI'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A8GK'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-ER-A19D'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-ER-A3ET'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A8GM'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-DA-A1HV'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2GE'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-WE-A8ZM'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-W3-AA1O'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-FS-A4F0'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2MM'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A185'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A1Q4'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-FS-A1ZG'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-D9-A6EG'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2GN'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2MR'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A3JH'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EB-A44R'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2GJ'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-DA-A1HW'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A17Z'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A29Q'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-FS-A4FC'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A3BZ'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2GD'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-D3-A8GQ'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A3JD'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-WE-A8ZY'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A2M8'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A17X'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A3AA'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-EE-A2M5'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-FR-A8YE'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-DA-A1IB'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-FS-A1ZK'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A5GR'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-HR-A2OH'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2A0'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-D3-A8GB'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A3MR'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A3J4'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-FS-A4FB'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-D3-A8GI'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-FS-A4F4'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A20H'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-FR-A8YD'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-EE-A2GH'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-W3-AA21'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=1, sample_id='TCGA-GN-A4U9'),\n",
       " Data(x=[50, 1], edge_index=[2, 40], y=0, sample_id='TCGA-ER-A3EV')]"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MyDataset(data_list[0:150])\n",
    "test_set = MyDataset(data_list[150:200])\n",
    "val_set = MyDataset(data_list[200:230])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyDataset(150)"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "range object index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/share/home/zhangqibin/CIDER/immune_mlp.ipynb Cell 85\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bg02/share/home/zhangqibin/CIDER/immune_mlp.ipynb#Y154sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m train_set[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bg02/share/home/zhangqibin/CIDER/immune_mlp.ipynb#Y154sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m x \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bg02/share/home/zhangqibin/CIDER/immune_mlp.ipynb#Y154sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m edge_index \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39medge_index\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/causal/lib/python3.9/site-packages/torch_geometric/data/dataset.py:197\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"In case :obj:`idx` is of type integer, will return the data object\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[39mat index :obj:`idx` (and transforms it in case :obj:`transform` is\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[39mpresent).\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[39mIn case :obj:`idx` is a slicing object, *e.g.*, :obj:`[2:5]`, a list, a\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[39mtuple, or a :obj:`torch.Tensor` or :obj:`np.ndarray` of type long or\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[39mbool, will return a subset of the dataset at the specified indices.\"\"\"\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39misinstance\u001b[39m(idx, (\u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39minteger))\n\u001b[1;32m    194\u001b[0m         \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(idx, Tensor) \u001b[39mand\u001b[39;00m idx\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m    195\u001b[0m         \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(idx, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39misscalar(idx))):\n\u001b[0;32m--> 197\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices()[idx])\n\u001b[1;32m    198\u001b[0m     data \u001b[39m=\u001b[39m data \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(data)\n\u001b[1;32m    199\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n",
      "\u001b[0;31mIndexError\u001b[0m: range object index out of range"
     ]
    }
   ],
   "source": [
    "data = train_set[0]\n",
    "x = data.x.to(device)\n",
    "edge_index = data.edge_index.to(device)\n",
    "y = data.y.to(device)\n",
    "y_pred = model(torch.tensor(x.float()), edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 105.1576\n",
      "Curr_Best: 0.4000, Val: 0.3200\n",
      "Epoch: 002, Loss: 104.4304\n",
      "Epoch: 003, Loss: 103.7919\n",
      "Curr_Best: 0.6000, Val: 0.6800\n",
      "Epoch: 004, Loss: 103.2154\n",
      "Epoch: 005, Loss: 102.7257\n",
      "Epoch: 006, Loss: 102.3928\n",
      "Epoch: 007, Loss: 102.3144\n",
      "Epoch: 008, Loss: 102.5641\n",
      "Epoch: 009, Loss: 103.0071\n",
      "Epoch: 010, Loss: 103.2818\n",
      "Epoch: 011, Loss: 103.2645\n",
      "Epoch: 012, Loss: 103.0568\n",
      "Epoch: 013, Loss: 102.7915\n",
      "Epoch: 014, Loss: 102.5608\n",
      "Epoch: 015, Loss: 102.4044\n",
      "Epoch: 016, Loss: 102.3252\n",
      "Epoch: 017, Loss: 102.3037\n",
      "Epoch: 018, Loss: 102.3096\n",
      "Epoch: 019, Loss: 102.3207\n",
      "Epoch: 020, Loss: 102.3264\n",
      "Epoch: 021, Loss: 102.3227\n",
      "Epoch: 022, Loss: 102.3105\n",
      "Epoch: 023, Loss: 102.2947\n",
      "Epoch: 024, Loss: 102.2869\n",
      "Epoch: 025, Loss: 102.2968\n",
      "Epoch: 026, Loss: 102.3307\n",
      "Epoch: 027, Loss: 102.3865\n",
      "Epoch: 028, Loss: 102.4470\n",
      "Epoch: 029, Loss: 102.4893\n",
      "Epoch: 030, Loss: 102.5011\n",
      "Epoch: 031, Loss: 102.4826\n",
      "Epoch: 032, Loss: 102.4434\n",
      "Epoch: 033, Loss: 102.3962\n",
      "Epoch: 034, Loss: 102.3517\n",
      "Epoch: 035, Loss: 102.3175\n",
      "Epoch: 036, Loss: 102.2952\n",
      "Epoch: 037, Loss: 102.2803\n",
      "Epoch: 038, Loss: 102.2716\n",
      "Epoch: 039, Loss: 102.2670\n",
      "Epoch: 040, Loss: 102.2657\n",
      "Epoch: 041, Loss: 102.2675\n",
      "Epoch: 042, Loss: 102.2729\n",
      "Epoch: 043, Loss: 102.2826\n",
      "Epoch: 044, Loss: 102.2963\n",
      "Epoch: 045, Loss: 102.3117\n",
      "Epoch: 046, Loss: 102.3241\n",
      "Epoch: 047, Loss: 102.3289\n",
      "Epoch: 048, Loss: 102.3235\n",
      "Epoch: 049, Loss: 102.3095\n",
      "Epoch: 050, Loss: 102.2915\n",
      "Epoch: 051, Loss: 102.2711\n",
      "Epoch: 052, Loss: 102.2531\n",
      "Epoch: 053, Loss: 102.2428\n",
      "Epoch: 054, Loss: 102.2412\n",
      "Epoch: 055, Loss: 102.2479\n",
      "Epoch: 056, Loss: 102.2612\n",
      "Epoch: 057, Loss: 102.2679\n",
      "Epoch: 058, Loss: 102.2639\n",
      "Epoch: 059, Loss: 102.2528\n",
      "Epoch: 060, Loss: 102.2397\n",
      "Epoch: 061, Loss: 102.2290\n",
      "Epoch: 062, Loss: 102.2242\n",
      "Epoch: 063, Loss: 102.2265\n",
      "Epoch: 064, Loss: 102.2328\n",
      "Epoch: 065, Loss: 102.2378\n",
      "Epoch: 066, Loss: 102.2362\n",
      "Epoch: 067, Loss: 102.2277\n",
      "Epoch: 068, Loss: 102.2207\n",
      "Epoch: 069, Loss: 102.2262\n",
      "Epoch: 070, Loss: 102.2407\n",
      "Epoch: 071, Loss: 102.2481\n",
      "Epoch: 072, Loss: 102.2399\n",
      "Epoch: 073, Loss: 102.2339\n",
      "Epoch: 074, Loss: 102.2410\n",
      "Epoch: 075, Loss: 102.2424\n",
      "Epoch: 076, Loss: 102.2292\n",
      "Epoch: 077, Loss: 102.2226\n",
      "Epoch: 078, Loss: 102.2365\n",
      "Epoch: 079, Loss: 102.2652\n",
      "Epoch: 080, Loss: 102.2740\n",
      "Epoch: 081, Loss: 102.2557\n",
      "Epoch: 082, Loss: 102.2401\n",
      "Epoch: 083, Loss: 102.2286\n",
      "Epoch: 084, Loss: 102.2132\n",
      "Epoch: 085, Loss: 102.2033\n",
      "Epoch: 086, Loss: 102.1992\n",
      "Epoch: 087, Loss: 102.1796\n",
      "Epoch: 088, Loss: 102.1779\n",
      "Epoch: 089, Loss: 102.1933\n",
      "Epoch: 090, Loss: 102.1925\n",
      "Epoch: 091, Loss: 102.1730\n",
      "Epoch: 092, Loss: 102.1902\n",
      "Epoch: 093, Loss: 102.2038\n",
      "Epoch: 094, Loss: 102.1769\n",
      "Epoch: 095, Loss: 102.1731\n",
      "Epoch: 096, Loss: 102.1840\n",
      "Epoch: 097, Loss: 102.1495\n",
      "Epoch: 098, Loss: 102.1325\n",
      "Epoch: 099, Loss: 102.1379\n",
      "Epoch: 100, Loss: 102.0958\n"
     ]
    }
   ],
   "source": [
    "from utils import evaluate_graphs_accuracy\n",
    "from models import GcnEncoderGraph\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss\n",
    "\n",
    "# training setting\n",
    "batch_size = 64\n",
    "lr = 1e-2\n",
    "epochs = 100\n",
    "num_workers = 16\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "model = GcnEncoderGraph(input_dim=train_set.num_features,\n",
    "                        hidden_dim=16,\n",
    "                        embedding_dim=16,\n",
    "                        num_layers=2,\n",
    "                        pred_hidden_dims=[],\n",
    "                        label_dim=2)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                lr=lr,\n",
    "                                weight_decay=1e-4)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "criterion = CrossEntropyLoss(weight=torch.tensor([0.4, 0.5]).to(device))\n",
    "# criterion = CrossEntropyLoss()\n",
    "\n",
    "model.to(device)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    optimizer.zero_grad()\n",
    "    for data in train_loader:\n",
    "        x = data.x.to(device)\n",
    "        edge_index = data.edge_index.to(device)\n",
    "        y = data.y.to(device)\n",
    "        batch = data.batch.to(device)\n",
    "        y_pred = model(x, edge_index, batch)\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "    optimizer.step()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss_all:.4f}')\n",
    "\n",
    "    if epoch % 2 == 1:\n",
    "        accuracy_test = evaluate_graphs_accuracy(val_loader, model, device)\n",
    "        if accuracy_test > best_accuracy:\n",
    "            torch.save(model.state_dict(), './params/immune_selected.ckpt')\n",
    "            best_accuracy = accuracy_test\n",
    "            accuracy_val = evaluate_graphs_accuracy(test_loader, model, device)\n",
    "            print(f'Curr_Best: {best_accuracy:.4f}, Val: {accuracy_val:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6267)"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "for data in train_set:\n",
    "    sum += data.y\n",
    "1-sum/len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6000)"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "for data in val_set:\n",
    "    sum += data.y\n",
    "1-sum/len(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6800)"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "for data in test_set:\n",
    "    sum += data.y\n",
    "1-sum/len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6348)"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "for data in data_list:\n",
    "    sum += data.y\n",
    "1-sum/len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./params/immune_selected.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_graphs_accuracy(test_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_graphs_accuracy(val_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "for data in val_loader:\n",
    "    output = model(\n",
    "        data.x.to(device),\n",
    "        data.edge_index.to(device),\n",
    "        data.batch.to(device),\n",
    "    )\n",
    "    predictions = output.argmax(dim=1).cpu().numpy().reshape(-1)\n",
    "    # labels = data.y.cpu().numpy().reshape(-1)\n",
    "    sum += predictions.sum()\n",
    "1 - sum/len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "for data in test_loader:\n",
    "    output = model(\n",
    "        data.x.to(device),\n",
    "        data.edge_index.to(device),\n",
    "        data.batch.to(device),\n",
    "    )\n",
    "    predictions = output.argmax(dim=1).cpu().numpy().reshape(-1)\n",
    "    # labels = data.y.cpu().numpy().reshape(-1)\n",
    "    sum += predictions.sum()\n",
    "1 - sum/len(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_complete = torch.ones([50, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import dense_to_sparse\n",
    "\n",
    "edge_index_complete, _ = dense_to_sparse(adj_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "data_list = []\n",
    "for i in range(len(sample_ids)):\n",
    "    data = Data(x=node_features[i].unsqueeze(1), edge_index=edge_index_complete, y=graph_labels[i], sample_id=sample_ids[i])\n",
    "    data_list.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 104.2298\n",
      "Curr_Best: 0.5667, Val: 0.7400\n",
      "Epoch: 002, Loss: 104.2001\n",
      "Epoch: 003, Loss: 104.1727\n",
      "Epoch: 004, Loss: 104.1476\n",
      "Epoch: 005, Loss: 104.1248\n",
      "Epoch: 006, Loss: 104.1043\n",
      "Epoch: 007, Loss: 104.0863\n",
      "Epoch: 008, Loss: 104.0706\n",
      "Epoch: 009, Loss: 104.0574\n",
      "Epoch: 010, Loss: 104.0466\n",
      "Epoch: 011, Loss: 104.0385\n",
      "Epoch: 012, Loss: 104.0331\n",
      "Epoch: 013, Loss: 104.0305\n",
      "Epoch: 014, Loss: 104.0308\n",
      "Epoch: 015, Loss: 104.0340\n",
      "Curr_Best: 0.6000, Val: 0.7200\n",
      "Epoch: 016, Loss: 104.0398\n",
      "Epoch: 017, Loss: 104.0485\n",
      "Epoch: 018, Loss: 104.0596\n",
      "Epoch: 019, Loss: 104.0731\n",
      "Epoch: 020, Loss: 104.0884\n",
      "Epoch: 021, Loss: 104.1054\n",
      "Epoch: 022, Loss: 104.1233\n",
      "Epoch: 023, Loss: 104.1417\n",
      "Epoch: 024, Loss: 104.1598\n",
      "Epoch: 025, Loss: 104.1771\n",
      "Epoch: 026, Loss: 104.1929\n",
      "Epoch: 027, Loss: 104.2066\n",
      "Epoch: 028, Loss: 104.2178\n",
      "Epoch: 029, Loss: 104.2263\n",
      "Epoch: 030, Loss: 104.2318\n",
      "Epoch: 031, Loss: 104.2343\n",
      "Epoch: 032, Loss: 104.2340\n",
      "Epoch: 033, Loss: 104.2309\n",
      "Epoch: 034, Loss: 104.2254\n",
      "Epoch: 035, Loss: 104.2178\n",
      "Epoch: 036, Loss: 104.2084\n",
      "Epoch: 037, Loss: 104.1976\n",
      "Epoch: 038, Loss: 104.1856\n",
      "Epoch: 039, Loss: 104.1730\n",
      "Epoch: 040, Loss: 104.1599\n",
      "Epoch: 041, Loss: 104.1467\n",
      "Epoch: 042, Loss: 104.1336\n",
      "Epoch: 043, Loss: 104.1207\n",
      "Epoch: 044, Loss: 104.1084\n",
      "Epoch: 045, Loss: 104.0966\n",
      "Epoch: 046, Loss: 104.0856\n",
      "Epoch: 047, Loss: 104.0752\n",
      "Epoch: 048, Loss: 104.0657\n",
      "Epoch: 049, Loss: 104.0571\n",
      "Epoch: 050, Loss: 104.0492\n",
      "Epoch: 051, Loss: 104.0422\n",
      "Epoch: 052, Loss: 104.0360\n",
      "Epoch: 053, Loss: 104.0306\n",
      "Epoch: 054, Loss: 104.0256\n",
      "Epoch: 055, Loss: 104.0214\n",
      "Epoch: 056, Loss: 104.0176\n",
      "Epoch: 057, Loss: 104.0136\n",
      "Epoch: 058, Loss: 104.0094\n",
      "Epoch: 059, Loss: 104.0058\n",
      "Epoch: 060, Loss: 104.0027\n",
      "Epoch: 061, Loss: 104.0000\n",
      "Epoch: 062, Loss: 103.9974\n",
      "Epoch: 063, Loss: 103.9952\n",
      "Epoch: 064, Loss: 103.9933\n",
      "Epoch: 065, Loss: 103.9915\n",
      "Epoch: 066, Loss: 103.9897\n",
      "Epoch: 067, Loss: 103.9884\n",
      "Epoch: 068, Loss: 103.9875\n",
      "Epoch: 069, Loss: 103.9865\n",
      "Epoch: 070, Loss: 103.9850\n",
      "Epoch: 071, Loss: 103.9831\n",
      "Epoch: 072, Loss: 103.9808\n",
      "Epoch: 073, Loss: 103.9781\n",
      "Epoch: 074, Loss: 103.9750\n",
      "Epoch: 075, Loss: 103.9712\n",
      "Epoch: 076, Loss: 103.9674\n",
      "Epoch: 077, Loss: 103.9640\n",
      "Epoch: 078, Loss: 103.9606\n",
      "Epoch: 079, Loss: 103.9565\n",
      "Epoch: 080, Loss: 103.9514\n",
      "Epoch: 081, Loss: 103.9467\n",
      "Epoch: 082, Loss: 103.9412\n",
      "Epoch: 083, Loss: 103.9363\n",
      "Epoch: 084, Loss: 103.9310\n",
      "Epoch: 085, Loss: 103.9252\n",
      "Epoch: 086, Loss: 103.9190\n",
      "Epoch: 087, Loss: 103.9127\n",
      "Epoch: 088, Loss: 103.9058\n",
      "Epoch: 089, Loss: 103.8984\n",
      "Epoch: 090, Loss: 103.8922\n",
      "Epoch: 091, Loss: 103.8873\n",
      "Epoch: 092, Loss: 103.8816\n",
      "Epoch: 093, Loss: 103.8752\n",
      "Epoch: 094, Loss: 103.8702\n",
      "Epoch: 095, Loss: 103.8649\n",
      "Epoch: 096, Loss: 103.8595\n",
      "Epoch: 097, Loss: 103.8539\n",
      "Epoch: 098, Loss: 103.8478\n",
      "Epoch: 099, Loss: 103.8413\n",
      "Epoch: 100, Loss: 103.8343\n"
     ]
    }
   ],
   "source": [
    "from utils import evaluate_graphs_accuracy\n",
    "from models import GcnEncoderGraph\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss\n",
    "\n",
    "# training setting\n",
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "epochs = 100\n",
    "num_workers = 16\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "model = GcnEncoderGraph(input_dim=train_set.num_features,\n",
    "                        hidden_dim=8,\n",
    "                        embedding_dim=16,\n",
    "                        num_layers=3,\n",
    "                        pred_hidden_dims=[],\n",
    "                        label_dim=2)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                lr=lr,\n",
    "                                weight_decay=1e-4)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "criterion = CrossEntropyLoss(weight=torch.tensor([0.4, 0.6]).to(device))\n",
    "# criterion = CrossEntropyLoss()\n",
    "\n",
    "model.to(device)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    optimizer.zero_grad()\n",
    "    for data in train_loader:\n",
    "        x = data.x.to(device)\n",
    "        edge_index = data.edge_index.to(device)\n",
    "        y = data.y.to(device)\n",
    "        batch = data.batch.to(device)\n",
    "        y_pred = model(x, edge_index, batch)\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "    optimizer.step()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss_all:.4f}')\n",
    "\n",
    "    if epoch % 2 == 1:\n",
    "        accuracy_test = evaluate_graphs_accuracy(val_loader, model, device)\n",
    "        if accuracy_test > best_accuracy:\n",
    "            torch.save(model.state_dict(), './params/immune_complete.ckpt')\n",
    "            best_accuracy = accuracy_test\n",
    "            accuracy_val = evaluate_graphs_accuracy(test_loader, model, device)\n",
    "            print(f'Curr_Best: {best_accuracy:.4f}, Val: {accuracy_val:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./params/immune_complete.ckpt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
